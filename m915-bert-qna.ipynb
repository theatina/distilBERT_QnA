{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"___\n\n# M915 - Συστήματα Κατανόησης και Παραγωγής Κειμένου <br> <span style=\"font-size:6mm;\"> Assignment 2 </span> <br><br> <span style=\"font-size:5mm;\"> Kylafi Christina-Theano </span> <br> <span style=\"font-size:4mm;\"> LT1200012 </span>\n---\n---","metadata":{}},{"cell_type":"markdown","source":"## Imports\n---","metadata":{}},{"cell_type":"code","source":"# import Python libraries\n\n# essentials\nimport os\nimport random\nfrom random import sample\nimport numpy as np\nfrom numpy import mean, std\nimport math\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport json\nfrom collections import Counter\nimport re, string, unicodedata\nimport pickle \nfrom datetime import datetime\nimport pytz\nfrom itertools import cycle\nfrom scipy import interp \nimport time\nimport copy\nimport json\nimport csv\nfrom ast import literal_eval\n\n# PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\n\n# SKLEARN\nimport sklearn\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import normalize, OneHotEncoder, label_binarize\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_squared_error, accuracy_score, f1_score, precision_score, recall_score, log_loss, plot_confusion_matrix, roc_curve, auc, roc_auc_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import utils\nfrom sklearn.svm import SVC\n\n# NLTK\nimport nltk\nfrom nltk import word_tokenize, sent_tokenize, FreqDist\nfrom nltk.corpus import stopwords\nfrom nltk.stem import LancasterStemmer, WordNetLemmatizer\nnltk.download\nnltk.download('wordnet')\nnltk.download('stopwords')\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n\n!pip install datasets\nfrom datasets import load_metric\n\n# BERT\n# !pip install transformers\n# !pip install pytorch-pretrained-bert\n\nimport transformers\nfrom transformers.data.processors.squad import SquadV2Processor\nfrom transformers.data import squad_convert_examples_to_features\nfrom transformers import AutoTokenizer\nfrom transformers import BertTokenizer, BertModel, BertForPreTraining, BertTokenizerFast, AdamW, BertForQuestionAnswering, DistilBertTokenizer, DistilBertForQuestionAnswering, DistilBertTokenizerFast, DistilBertModel\nfrom torch.utils.data import DataLoader\nfrom transformers import AdamW\n# from tqdm import tqdm_notebook as tqdm\nfrom tqdm import tqdm\n\nimport warnings\n\n# MORE INSTALLATIONS & IMPORTS\n# !pip install yellowbrick\n# !pip install advertools\n# !pip install vaderSentiment\n# !pip install ekphrasis\n# !pip install tweet-preprocessor\n\nfrom wordcloud import WordCloud\n# import advertools as adv\n# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n# from ekphrasis.classes.segmenter import Segmenter\n# import preprocessor as p\nimport multiprocessing\nfrom shutil import copy\nimport seaborn as sns\nfrom gensim.models import Word2Vec\nfrom IPython.display import Image, FileLink, FileLinks, clear_output\nfrom ast import literal_eval\nfrom tqdm.notebook import tqdm\n# clear_output()\n\nprint(\"\\nImports Done !\\n\")\n\n# Device settings\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(f\"Working on {device}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-27T14:55:12.486655Z","iopub.execute_input":"2022-08-27T14:55:12.487226Z","iopub.status.idle":"2022-08-27T14:55:35.669712Z","shell.execute_reply.started":"2022-08-27T14:55:12.487170Z","shell.execute_reply":"2022-08-27T14:55:35.668218Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.12.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.5.0)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.8.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\nImports Done !\n\nWorking on cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Functions\n---","metadata":{}},{"cell_type":"code","source":"# Functions\n\n# convert squad dataset to dataframe by extracting the necessary info\ndef squad_df(file_path, record_path=['data','paragraphs','qas','answers']):\n    file = json.loads(open(file_path).read())\n    \n    # parsing different level's in the json file\n    js = pd.json_normalize(file, record_path)\n    m = pd.json_normalize(file, record_path[:-1])\n    r = pd.json_normalize(file,record_path[:-2])\n    \n    # combining it into single dataframe\n    idx = np.repeat(r['context'].values, r.qas.str.len())\n    m['context'] = idx\n    data = m[['id','context','question','answers']].set_index('id').reset_index()\n    # keep the text sequence number for later\n    data['context_id'] = data['context'].factorize()[0]\n    return data\n\n\n# Add answer ending index\ndef add_ans_ind(qna_df):\n    texts = qna_df[\"context\"]\n    answers = qna_df[\"answers\"]\n    for row,(text,answers) in enumerate(zip(texts,answers)):\n        for a_num,a in enumerate(answers):\n            a_text = a[\"text\"]\n            a_start = a[\"answer_start\"]\n            a_end = a_start\n            \n            a_end = int(a_start+len(a_text))\n            if text[a_start:a_end] == a_text:\n                qna_df.loc[row,\"answers\"][a_num][\"answer_end\"]=a_end\n            else:\n                if a_start==0:\n                    continue\n                else:\n                    if a_start==1:\n                        if text[a_start-1:a_end-1] == a_text:\n                            qna_df.loc[row,\"answers\"][a_num][\"answer_start\"]= a_start - 1\n                            qna_df.loc[row,\"answers\"][a_num][\"answer_end\"]= a_end - 1\n\n                    else:\n                        if text[a_start-2:a_end-2] == a_text:\n                            qna_df.loc[row,\"answers\"][a_num][\"answer_start\"]= a_start - 2\n                            qna_df.loc[row,\"answers\"][a_num][\"answer_end\"]= a_end - 2\n\n    return qna_df\n\n\n# add the starting-ending positions of answers (token-wise)\ndef add_token_positions(encodings, texts, starts, ends):\n    # initialize lists to contain the token indices of answer start/end\n    start_pos = []\n    end_pos = []\n    unanswerable_pos = tokenizer.model_max_length\n    for i,(text,start,end) in enumerate( zip(texts,starts,ends) ):\n        # unanswerable questions\n        if start==end==len(text):\n            start_pos.append(unanswerable_pos)\n            end_pos.append(unanswerable_pos)\n            continue\n        else:\n            start_pos.append(encodings.char_to_token(i, start))\n            end_pos.append(encodings.char_to_token(i, end))\n            if start_pos[-1] is None:\n                start_pos[-1] = unanswerable_pos\n                end_pos[-1] = unanswerable_pos\n                continue\n           \n            shift = 1\n            while end_pos[-1] is None and end-shift>start:\n                end_pos[-1] = encodings.char_to_token(i, end - shift)\n                shift += 1\n            if end_pos[-1] is None:\n                start_pos[-1] = unanswerable_pos\n                end_pos[-1] = unanswerable_pos\n\n    encodings.update({'start_positions': start_pos, 'end_positions': end_pos})\n\n# apply function to our data\n# add_token_positions(dev_encodings, list(qna_dev_df['AnswerStart']), list(qna_dev_df['AnswerEnd']))\n\n\ndef save_json_evalsquad1(total_preds,filepath=\"preds.json\", dev_set=\"/content/dev-v2.0.json\"):\n    with open(filepath, \"w\") as outfile:\n        json.dump(ast.literal_eval(json.dumps(total_preds)), outfile)\n    \n#     !python3 /content/evaluate-v2.0.py {dev_set} {filepath}\n    !python3 /kaggle/input/bert-code/bert/evaluate.py {dev_set} {filepath} \n\n    \ndef get_prediction(qid,total_preds):\n    return total_preds[qid]\n\ndef normalize_text(s):\n    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n    import string, re\n\n    def remove_articles(text):\n        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n        return re.sub(regex, \" \", text)\n\n    def white_space_fix(text):\n        return \" \".join(text.split())\n\n    def remove_punc(text):\n        exclude = set(string.punctuation)\n        return \"\".join(ch if ch not in exclude else \" \" for ch in text)\n\n    def lower(text):\n        return text.lower()\n\n    return white_space_fix(remove_articles(remove_punc(lower(s))))\n\n\ndef compute_exact_match(prediction, truth):\n    return int(normalize_text(prediction) == normalize_text(truth))\n\ndef compute_f1(prediction, truth):\n    pred_tokens = normalize_text(prediction).split()\n    truth_tokens = normalize_text(truth).split()\n    \n    print(pred_tokens,truth_tokens)\n    \n    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n        return int(pred_tokens == truth_tokens)\n    \n    common_tokens = set(pred_tokens) & set(truth_tokens)\n    \n    # if there are no common tokens then f1 = 0\n    if len(common_tokens) == 0:\n        return 0\n    \n    prec = len(common_tokens) / len(pred_tokens)\n    rec = len(common_tokens) / len(truth_tokens)\n    \n    return 2 * (prec * rec) / (prec + rec)\n\n\n\ndef get_gold_answers(qid,id_to_answers):\n    \n    gold_answers = [answer[\"text\"] for answer in id_to_answers[qid] if answer[\"text\"]]\n\n    # if gold_answers doesn't exist it's because this is a negative example - \n    # the only correct answer is an empty string\n    if not gold_answers:\n        gold_answers = [\"\"]\n    \n    return gold_answers\n\ndef evalEMandF1_squad1(dev_df,total_preds,model_dir):\n    global id_to_answers\n    questions = [  q for q in dev_df[\"question\"].values  ]\n    id_s = [ i for i in dev_df[\"id\"].values ]\n    answer_s = [ ans for ans in dev_df[\"answers\"].values ]\n    \n#     id_to_answers = {k:v for k,v in zip(id_s,answer_s)}\n    em_score = []\n    f1_score = []\n\n#   logfile for predictions and true answers\n    logfile_name = \"model_preds.txt\"\n    logfile_path = os.path.join( os.path.join(model_dir),logfile_name)\n    logfile = open(logfile_path, \"w\", encoding=\"utf-8\")\n    logfile.write(\"Best Model Question Predictions on Dev Set\\n\")\n    for num,(qid,quest) in enumerate(zip(id_s,questions)):\n        prediction = get_prediction(qid,total_preds)\n        true_answers = get_gold_answers(qid,id_to_answers)\n\n        em_score.append(max((compute_exact_match(prediction, answer)) for answer in true_answers))\n        f1_score.append(max((compute_f1(prediction, answer)) for answer in true_answers))\n        \n        log_str = f\"\\n\\n{num+1}. Question: {quest}\\nTrue Answer(s): {true_answers}\\nPrediction(s): {prediction}\\nEM: {bool(int(em_score[-1]))}\\nF1: {f1_score[-1]*100:.2f}%\"\n        logfile.write(log_str)\n    \n    logfile.close()\n    \n    em = sum(em_score)/len(id_s)*100\n    f1_mean = sum(f1_score)/len(id_s)*100\n    f1_max = max(f1_score)*100\n    score_str = f\"Dev Set Scores -- \\tEM: {em:.2f}% \\tF1 (mean): {f1_mean:.2f}% \\tF1 (max): {f1_max:.2f}%\\n\"\n    print(score_str)\n    return em,f1_mean,f1_max,score_str\n\n\ndef total_preds_list(model,dev_dataset,device,dev_df):\n    global id_to_answers\n    model.to(device)\n    model.eval()\n    # initialize list to store epoch accuracies\n\n    total_preds = {}\n    acc = []\n    gtruth = {}\n    predictions = {}\n\n    batch_size=64\n    val_loader = DataLoader(dev_dataset, batch_size=batch_size)\n    id_list = [ i for i in dev_df[\"id\"].values ]\n    batch_sizes= [ len(val_b[\"input_ids\"]) for val_b in val_loader]\n    batches=len(val_loader)\n    id_loader = [ id_list[i*batch_size:i*batch_size+batch_size] for i in range(batches-1) ]\n    id_loader.append( id_list[- batch_sizes[-1] :] )\n#     print(id_loader, batch_sizes, batches)\n\n    # create a dictionary to link question id's with answers\n    questions = [  q for q in dev_df[\"question\"].values  ]\n#     id_list = [ i for i in dev_df[\"id\"].values ]\n    answer_s = [ ans for ans in dev_df[\"answers\"].values ]\n    \n    loss_dev = 0\n    loop_dev = tqdm(val_loader,leave=True)\n    for batch,ids in zip(val_loader, id_loader):\n        # we don't need to calculate gradients as we're not training\n        with torch.no_grad():\n            # pull batched items from loader\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            # we will use true positions for accuracy calc\n    #         start_true = batch['start_positions'].to(device)\n    #         end_true = batch['end_positions'].to(device)\n            qid = ids\n            # make predictions\n            outputs = model(input_ids, attention_mask=attention_mask)\n#             loss = outputs[0]\n#             loss_dev += loss.item()\n    #         print(outputs['start_logits'])\n            # pull prediction tensors out and argmax to get predicted tokens\n            start_pred = torch.argmax(outputs['start_logits'], dim=1)\n            end_pred = torch.argmax(outputs['end_logits'], dim=1)\n\n    #         ans_pred_list = [ (question_id,p) for question_id,p in zip(qid,preds) ]\n            preds = [ tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[num][start_pred[num]:end_pred[num]])) for num in range(len(qid)) ]\n            total_preds.update({ q:pred for q,pred in zip(qid,preds) })\n            \n            loop_dev.update(1)\n\n    return total_preds\n\n\ndef log_model(logfile,datetime_info,model,model_name,loss_func,optimizer,batch_size,normalization,max_s_len,pretrained):\n    separator = \"\".join([ \"_\" for i in range(50) ])\n    logstring = \"\"\n\n    # logstring+= f\"\\n\\n\\n\\n{separator}\\n{separator}\\n\\n\"\n    logstring+= f\"{datetime_info} - {model_name}\\n\\n\"\n    logstring+= f\"Features: {model.embedding.embedding_dim}\\n\"\n    logstring+= f\"Max Sentence length: {max_s_len}\\n\"\n    logstring+= f\"Pretrained Embeddings: {pretrained}\\n\"\n    logstring+= f\"Normalization: {normalization}\\n\"\n    # logstring+= f\"Epochs: {epochs}\\n\"\n    logstring+= f\"Batch size: {batch_size}\\n\"\n    logstring+= f\"Optimizer: {optimizer}\\n\"\n    logstring+= f\"Loss function: {loss_func}\"\n    if type(loss_func) == torch.nn.CrossEntropyLoss:\n        logstring+= f\", weight: {loss_func.weight}\\n\"\n    else :\n        logstring+= \"\\n\"\n        logstring+= f\"Layers: {model}\\n\\n\"\n        logstring+= f\"{separator}\\n\\n\"\n\n    logfile.write(logstring)\n\n\ndef log_score(logfile,epoch,model,score_str):\n    separator = \"\".join([ \"_\" for i in range(50) ])\n    logstring = \"\"\n\n    logstring+= f\"\\n\\n\\n> Epoch:{epoch}\\n\"\n    logstring+= score_str\n\n\n    logfile.write(logstring)\n\n\n# Logfiles\ndef get_file_ptr(drive_path,model_name):\n    tz = pytz.timezone('Europe/Athens')\n    datetime_info = f\"{datetime.now(tz):%d%m%y_%H%M}\"\n\n    logfile_name = f\"{model_name}__{datetime_info}.txt\"\n    model_logfile_dir_path = os.path.join(drive_path, f\"Results/Logfiles/{logfile_name[:-4]}\") \n    if not os.path.exists(model_logfile_dir_path):\n        os.makedirs(model_logfile_dir_path)  \n\n    logfile_path = os.path.join( os.path.join(model_logfile_dir_path),logfile_name)\n    logfile = open(logfile_path, \"w\", encoding=\"utf-8\")\n\n    return logfile, datetime_info, model_logfile_dir_path, logfile_path\n\n\ndef log_model_bert(logfile,datetime_info,model_name,optimizer,batch_size,max_s_len,train_len,val_len):\n    separator = \"\".join([ \"_\" for i in range(50) ])\n    logstring = \"\"\n\n    # logstring+= f\"\\n\\n\\n\\n{separator}\\n{separator}\\n\\n\"\n    logstring+= f\"{datetime_info} - {model_name}\\n\\n\"\n    logstring+= f\"Max Sentence length: {max_s_len}\\n\"\n    logstring+= f\"Batch size: {batch_size}\\n\"\n    logstring+= f\"Optimizer: {optimizer}\\n\"\n    logstring+= f\"Training Data: {train_len}\\n\"\n    logstring+= f\"Validation Data: {val_len}\\n\"\n    #   logstring+= f\"Layers: {model}\\n\\n\"\n    logstring+= f\"{separator}\\n\\n\"\n\n    logfile.write(logstring)\n    \n  \ndef preprocess_function(examples, tokenizer):\n    questions = [ q.strip() for q in list(examples[\"question\"])]\n    inputs = tokenizer(\n        questions,\n        list(examples[\"context\"]),\n        max_length=tokenizer.model_max_length,\n        truncation=\"only_second\",\n        return_offsets_mapping=True,\n        padding=\"max_length\")\n\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    answers = examples[\"answers\"].values\n    start_positions = []\n    end_positions = []\n\n    for i, offset in enumerate(offset_mapping):\n        if type(answers[i])==type(str):\n            answer = eval(answers[i][0])\n        else:\n            answer = answers[i][0]\n        start_char = answer[\"answer_start\"]\n        end_char = start_char + len(answer[\"text\"])\n        sequence_ids = inputs.sequence_ids(i)\n\n        # Find the start and end of the context\n        idx = 0\n        while sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n        while sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        # If the answer is not fully inside the context, label it (0, 0)\n        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            # Otherwise it's the start and end token positions\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs\n\ndef answer_a_question(question,text,tokenizer,model):\n    model.to(device)\n    model.eval()\n    \n    \n    model_in=tokenizer.encode_plus(text, question, max_length=tokenizer.model_max_length, truncation=\"only_first\", padding='max_length', return_tensors='pt')\n    in_ids = model_in[\"input_ids\"].to(device)\n    mask = model_in[\"attention_mask\"].to(device)\n    \n    outputs = model(in_ids, attention_mask=mask)\n    start_pred = torch.argmax(outputs['start_logits'], dim=1).item()\n    end_pred = torch.argmax(outputs['end_logits'], dim=1).item()\n    \n    text_ids= model_in[\"input_ids\"][0]\n    text_tokens=tokenizer.convert_ids_to_tokens(text_ids)\n\n    tokens = tokenizer.convert_ids_to_tokens(text_ids[start_pred:end_pred+1])\n    answer = tokenizer.convert_tokens_to_string(tokens)\n    answer = normalize_text(answer).capitalize()\n    \n#     print(f\"\\nText: {text}\\nQuestion: {question}\\n\\nPredicted answer: {answer}\\n\")\n\n    return answer\n\n\n# Data Visualization\ndef data_stats(df, data_type):\n    plt.clf()\n    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n    enc = tokenizer(list(df['context']), truncation=False )\n    lens=[ len(i_id) for i_id in enc[\"input_ids\"] ]\n    print(max(lens))\n    plt.figure(figsize=(18,12))\n    plt.grid(True)\n    plt.title(f\"{data_type} Set Cumulative Sum\")\n    plt.hist(lens)\n    plt.savefig(os.path.join(results_path,f\"{data_type}_max_lens_Csum.png\"),dpi=300)\n    plt.show()\n\n    return lens\n\ndef bar_plotting_lens(lens, data_type, val_to_show):\n    plt.clf()\n    lens_df=pd.DataFrame(lens)\n    len_desc = [ len for len in lens_df[0].value_counts().index[:val_to_show].tolist() ]\n    len_freq = [ freq for freq in lens_df[0].value_counts().tolist( )[:val_to_show] ]\n    fig = plt.figure(figsize =(48, 6))\n    bar_plot = plt.bar(len_desc, len_freq)\n    max_freq_ind = len_freq.index(max(len_freq))\n    bar_plot[max_freq_ind].set_color('m')\n    plt.xticks(len_desc)\n    plt.xlabel('Length')\n    plt.ylabel('Num of Texts')\n    plt.title(f\"{data_type} set context length\")\n    plt.grid(True)\n    # show plot\n    plt.savefig(os.path.join(results_path,f\"{data_type}_max_lens.png\"),dpi=300)\n    plt.show()\n    return len_desc[max_freq_ind]\n\ndef perc_Csum(lens, data_type):\n    len_vals=[50,100,150,200,256,300,512, max(lens)+1]\n    print(f\"\\nPercentage of {data_type} set context under:\")\n    for L in len_vals:\n        # plot cumulative summary and percentage of samples with context under length L\n         print(f\"{L} -> {sum([i<L for i in lens])/len(lens)*100:.2f}%\")\n    \n\n# pr_list = add_ans_ind(qna_train_df_quac)\n# pr_list = add_ans_ind(qna_dev_df_quac)","metadata":{"execution":{"iopub.status.busy":"2022-08-27T17:18:33.054827Z","iopub.execute_input":"2022-08-27T17:18:33.055253Z","iopub.status.idle":"2022-08-27T17:18:33.184134Z","shell.execute_reply.started":"2022-08-27T17:18:33.055219Z","shell.execute_reply":"2022-08-27T17:18:33.183099Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"## SQuADv1.1 Dataset\n---\n\n#### Steps:\n1. Add data \n2. Search for \"bert-code\" (https://www.kaggle.com/datasets/rndmnub/bert-code)\n\nor\n\n1. Save \"train-v1.1.json\" & \"dev-v1.1.json\" \n2. Change the \"squad_train_path\" & \"squad_dev_path\" variables below","metadata":{}},{"cell_type":"code","source":"# directories' paths\nsquad_train_path = \"/kaggle/input/bert-code/bert/train-v1.1.json\"\nsquad_dev_path = \"/kaggle/input/bert-code/bert/dev-v1.1.json\"\ntrain_df = squad_df(squad_train_path)\ndev_df = squad_df(squad_dev_path)\n\n# decrease train dataset for quicker training process\n# train_df = train_df.sample(frac=1).reset_index(drop=True)\n# train_df = train_df[: int(train_df.shape[0]/2)]\n# print(train_df.shape)\n\n# eval_v1_path = \"/kaggle/input/bert-code/bert/evaluate.py\"\n# eval_v2_path = \"/kaggle/input/httpsgithubcomsomiltgbert/evaluate-v2.0.py\"\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-25T21:37:12.557225Z","iopub.execute_input":"2022-08-25T21:37:12.557570Z","iopub.status.idle":"2022-08-25T21:37:18.640854Z","shell.execute_reply.started":"2022-08-25T21:37:12.557547Z","shell.execute_reply":"2022-08-25T21:37:18.639687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results directory\nresults_path = \"/kaggle/working/results\" #change it if not run in Kaggle environment\nif not os.path.exists(results_path):\n    os.makedirs(results_path)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T21:33:54.021716Z","iopub.execute_input":"2022-08-25T21:33:54.022156Z","iopub.status.idle":"2022-08-25T21:33:54.027911Z","shell.execute_reply.started":"2022-08-25T21:33:54.022119Z","shell.execute_reply":"2022-08-25T21:33:54.027139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization\n---","metadata":{}},{"cell_type":"code","source":"# plot counts of N_max biggest length values of context in the dataset \nN_max=50\nlens_train = data_stats(train_df, \"Train\")\nbar_plotting_lens(lens_train,\"Train\", N_max)\n\nlens_dev = data_stats(dev_df, \"Dev\")\nbar_plotting_lens(lens_dev,\"Dev\", N_max)\n\n# plot cumulative sum and percentage of samples with context under length L\nperc_Csum(lens_train, \"Train\")\nperc_Csum(lens_dev, \"Dev\")\n\nFileLinks(\".\")","metadata":{"execution":{"iopub.status.busy":"2022-08-25T20:28:19.944968Z","iopub.execute_input":"2022-08-25T20:28:19.945214Z","iopub.status.idle":"2022-08-25T20:28:48.510569Z","shell.execute_reply.started":"2022-08-25T20:28:19.945190Z","shell.execute_reply":"2022-08-25T20:28:48.509572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Pre-Processing\n---","metadata":{}},{"cell_type":"code","source":"# clean GPU cache\nimport gc\nimport torch\ndef clean_GPU_cache(print_sum=False):\n    if print_sum:  \n        print(\"\\nBefore\\n\")\n        print(torch.cuda.memory_summary(device=device, abbreviated=False))\n    torch.cuda.memory_summary(device=None, abbreviated=False)\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    if print_sum:  \n        print(\"\\n\\nAfter\\n\")\n        print(torch.cuda.memory_summary(device=device, abbreviated=False))\n\ndef check_gpu():\n    clean_GPU_cache()\n    print(\"\\n\")\n    !nvidia-smi\n    print(\"\\n\")\n\n# clean_GPU_cache()","metadata":{"execution":{"iopub.status.busy":"2022-07-28T07:40:29.579946Z","iopub.execute_input":"2022-07-28T07:40:29.580518Z","iopub.status.idle":"2022-07-28T07:40:29.592608Z","shell.execute_reply.started":"2022-07-28T07:40:29.580476Z","shell.execute_reply":"2022-07-28T07:40:29.591241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load distilBERT tokenizer & model\ntokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\ntokenizer.model_max_length = 256\n\n# tokenize - truncate or pad only context if needed \ntrain_encodings = tokenizer(list(train_df['context']), list(train_df['question']), max_length=tokenizer.model_max_length, truncation=\"only_first\", padding='max_length')\ndev_encodings = tokenizer(list(dev_df['context']), list(dev_df['question']), max_length=tokenizer.model_max_length, truncation=\"only_first\", padding='max_length')\n\n# create the train/test encodings\n# reference: https://huggingface.co/docs/transformers/tasks/question_answering\n# train_encodings = preprocess_function(train_df, tokenizer)\n# dev_encodings = preprocess_function(dev_df, tokenizer)\n\n# id to answers dictionary\nglobal id_to_answers\nid_to_answers = { id_num:ans for id_num,ans in zip( dev_df[\"id\"].values, dev_df[\"answers\"].values ) }","metadata":{"execution":{"iopub.status.busy":"2022-07-28T07:40:29.594634Z","iopub.execute_input":"2022-07-28T07:40:29.596456Z","iopub.status.idle":"2022-07-28T07:41:09.539292Z","shell.execute_reply.started":"2022-07-28T07:40:29.596398Z","shell.execute_reply":"2022-07-28T07:41:09.538177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data processing\n# add end offset to the answers dictionaries\ntrain_df=add_ans_ind(train_df)\ndev_df=add_ans_ind(dev_df)\n\nanswer_starts_train=[ ans[0][\"answer_start\"] for ans in train_df[\"answers\"].values ]\nanswer_ends_train=[ ans[0][\"answer_end\"] for ans in train_df[\"answers\"].values ]\ntrain_encodings.update({\"start\":answer_starts_train, \"end\":answer_ends_train})\n\nanswer_starts=[ ans[0][\"answer_start\"] for ans in dev_df[\"answers\"].values ]\nanswer_ends=[ ans[0][\"answer_end\"] for ans in dev_df[\"answers\"].values ]\ndev_encodings.update({\"start\":answer_starts, \"end\":answer_ends})\n\nadd_token_positions(train_encodings, train_df[\"context\"], answer_starts_train, answer_ends_train)\n\n# create dataaframes with useful information\ntrain_enc_df=pd.DataFrame({ k:train_encodings[k] for k in train_encodings.keys() })\ndev_enc_df=pd.DataFrame({ k:dev_encodings[k] for k in dev_encodings.keys() })\n\n# save encodings\n# train_df.to_csv(os.path.join(results_path,f\"SQuADv1_train_encodings_{tokenizer.model_max_length}.csv\"), index=False, header=True)\n# dev_df.to_csv(os.path.join(results_path,f\"SQuADv1_dev_encodings_{tokenizer.model_max_length}.csv\"), index=False, header=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-28T07:41:09.540759Z","iopub.execute_input":"2022-07-28T07:41:09.541225Z","iopub.status.idle":"2022-07-28T07:41:11.262055Z","shell.execute_reply.started":"2022-07-28T07:41:09.541187Z","shell.execute_reply":"2022-07-28T07:41:11.260911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load encodings df\n# train_enc_path=f\"/kaggle/input/squadv1-encodings-bert{tokenizer.model_max_length}/SQuADv1_train_encodings_{tokenizer.model_max_length}.csv\"\n# train_encodings=pd.read_csv(train_enc_path)\n# dev_enc_path=f\"/kaggle/input/squadv1-encodings-bert{tokenizer.model_max_length}/SQuADv1_dev_encodings_{tokenizer.model_max_length}.csv\"\n# dev_encodings=pd.read_csv(dev_enc_path)\n\n# # keep half the data due to computational complexity\n# train_encodings=train_encodings[:int(train_encodings.shape[0]/4)]\n# print(train_encodings.shape[0])\n\n# # converse to dictionaries\n# train_encodings={ k:train_encodings[k].values for k in train_encodings.columns  }\n# dev_encodings={ k:dev_encodings[k].values for k in dev_encodings.columns  }","metadata":{"execution":{"iopub.status.busy":"2022-07-27T16:53:24.348209Z","iopub.execute_input":"2022-07-27T16:53:24.348589Z","iopub.status.idle":"2022-07-27T16:53:25.627115Z","shell.execute_reply.started":"2022-07-27T16:53:24.348558Z","shell.execute_reply":"2022-07-27T16:53:25.626115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTinput(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, ind):\n        return {key: torch.tensor(value[ind]) for key,value in self.encodings.items()}\n\n    def __len__(self):\n        return len(self.encodings.input_ids)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-28T07:41:11.265337Z","iopub.execute_input":"2022-07-28T07:41:11.265845Z","iopub.status.idle":"2022-07-28T07:41:11.272958Z","shell.execute_reply.started":"2022-07-28T07:41:11.265804Z","shell.execute_reply":"2022-07-28T07:41:11.271770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nclean_GPU_cache()\nbatch_size=32\n\n# build datasets for both our training and validation sets\ntrain_dataset = BERTinput(train_encodings)\ndev_dataset = BERTinput(dev_encodings)\n\n# initialize data loader for training data\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n# initialize validation set data loader\nval_loader = DataLoader(dev_dataset, batch_size=batch_size)\n\n# with open(f'/kaggle/..../train_loader_{tokenizer.model_max_length}.pickle', 'wb') as handle:\n#     pickle.dump(train_loader, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2022-07-28T07:41:11.274546Z","iopub.execute_input":"2022-07-28T07:41:11.275317Z","iopub.status.idle":"2022-07-28T07:41:11.797208Z","shell.execute_reply.started":"2022-07-28T07:41:11.275280Z","shell.execute_reply":"2022-07-28T07:41:11.795520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training\n---","metadata":{}},{"cell_type":"code","source":"# model training\n\n# setup GPU/CPU\ncheck_gpu()\n\npretrained = 0\nif pretrained==0:\n    model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n    model.to(device)    \n    model_name = \"DistilBertSQuADv1\"\nelse:\n    model_name = \"DistilBertSQuADv1Pretrained\"\n\n\nmodel.train()\ntot_eps = 5\n# initialize adam optimizer with weight decay (reduces chance of overfitting)\nlr = 5e-5\n# optim = torch.optim.Adam(model.parameters(), lr=9e-6)\nweight_decay = 0.999\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n\nlogfile, datetime_info, model_logfile_dir_path, logfilefullpath = get_file_ptr(results_path,model_name)\nlog_model_bert(logfile,datetime_info,model_name,optimizer,batch_size,tokenizer.model_max_length,len(train_dataset),len(dev_dataset))\n\noverall_train_loss = []\noverall_dev_loss = []\nmax_f1_mean = -99\nem_scores = []\nf1_scores = []\nep = 0\nloss_dev = []\nfor epoch in range(tot_eps):\n    epoch_loss_train = 0\n    epoch_acc = 0\n    epoch_acc_dev = 0\n    epoch_loss_dev = 0\n    # set model to train mode\n    model.train()\n    # setup loop (we use tqdm for the progress bar)\n\n    loop = tqdm(train_loader, leave=True)\n    for batch in loop:\n        \n        # initialize calculated gradients (from prev step)\n        optimizer.zero_grad()\n        \n        # pull all the tensor batches required for training\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        start_positions = batch['start_positions'].to(device)\n        end_positions = batch['end_positions'].to(device)\n        \n        # train model on batch and return outputs (including loss)\n        outputs = model(input_ids, attention_mask=attention_mask,\n                        start_positions=start_positions,\n                        end_positions=end_positions)\n        # extract loss\n        loss = outputs[0]\n        # calculate loss for every parameter that needs grad update\n        loss.backward()\n        # update parameters\n        optimizer.step()\n        \n        # print relevant info to progress bar\n        loop.set_description(f'Epoch {epoch+1}')\n        loop.set_postfix(loss=loss.item())\n        loop.update(1)\n        \n        epoch_loss_train += loss.item()\n        \n    \n    ep_loss_train = epoch_loss_train / len(train_loader)\n    ep_loss_dev = epoch_loss_dev / len(val_loader)\n\n    # keeping loss for learning curve plots\n    overall_train_loss.append(ep_loss_train)\n\n    #     evaluation and EM & F1 scores\n    epoch_str = f'\\n----------------------- Epoch {epoch+1} / {tot_eps} -----------------------\\n' \n    print(epoch_str)\n    loss_str = f'Train Loss: {ep_loss_train:.3f}\\n'\n    print(loss_str)  \n    \n    tot_preds = total_preds_list(model,dev_dataset,device,dev_df)\n    em,f1_mean,f1_max,score_str = evalEMandF1_squad1(dev_df,tot_preds,model_logfile_dir_path)\n    em_scores.append(em)\n    f1_scores.append(f1_mean)\n    \n        # save best model\n    if f1_mean > max_f1_mean:\n        best_model= model\n        best_model_name=f\"DistilBertSquad1_stateDict_ep{epoch+1}_DevF1{f1_mean:.3f}.dict\"\n        best_model_path = os.path.join(model_logfile_dir_path,f\"DistilBertSquad1_stateDict_ep{epoch+1}_DevF1{f1_mean:.3f}.dict\")\n        torch.save(best_model.state_dict(), best_model_path)\n        \n        max_f1_mean = f1_mean\n        ep = epoch\n    \n    # write to logfile\n    logfile.write(\"\\n\"+epoch_str+loss_str)\n    logfile.write(\"\\n\"+score_str+\"\\n\\n\")\n    \n    \n# torch.save(model.state_dict(), PATH)\nlogfile.close()\nnew_dir_name = f\"{model_logfile_dir_path}_ep{ep+1}__DevF1{f1_scores[ep]:.2f}\"\nos.rename(model_logfile_dir_path,new_dir_name)      \nmodel_logfile_dir_path=new_dir_name","metadata":{"execution":{"iopub.status.busy":"2022-07-28T07:53:03.338488Z","iopub.execute_input":"2022-07-28T07:53:03.338865Z","iopub.status.idle":"2022-07-28T08:40:00.383889Z","shell.execute_reply.started":"2022-07-28T07:53:03.338828Z","shell.execute_reply":"2022-07-28T08:40:00.382732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display files as links to download\nFileLinks(model_logfile_dir_path)","metadata":{"execution":{"iopub.status.busy":"2022-07-28T07:50:57.780835Z","iopub.status.idle":"2022-07-28T07:50:57.781673Z","shell.execute_reply.started":"2022-07-28T07:50:57.781383Z","shell.execute_reply":"2022-07-28T07:50:57.781409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation\n---","metadata":{}},{"cell_type":"code","source":"best_model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\nbest_model_dict_path= os.path.join(model_logfile_dir_path, best_model_name)\n\nbest_model.load_state_dict(torch.load(best_model_dict_path))\n# best_model.load_state_dict(torch.load(f\"/kaggle/working/results/DistilBertSquad1_stateDict_ep2_DevF151.641.dict\"))\n\nbest_model.to(device)   \nm = best_model.eval()\n\ntotal_preds = total_preds_list(best_model,dev_dataset,device,dev_df)\nem,f1_mean,f1_max,score_str = evalEMandF1_squad1(dev_df,total_preds,model_logfile_dir_path)\n\nFileLinks(\".\")","metadata":{"execution":{"iopub.status.busy":"2022-07-28T08:43:26.664363Z","iopub.execute_input":"2022-07-28T08:43:26.665318Z","iopub.status.idle":"2022-07-28T08:44:12.793611Z","shell.execute_reply.started":"2022-07-28T08:43:26.665280Z","shell.execute_reply":"2022-07-28T08:44:12.792293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions\n---","metadata":{}},{"cell_type":"code","source":"results_path = \"/kaggle/working/results/predictions\" #change it if not run in Kaggle environment\nif not os.path.exists(results_path):\n    os.makedirs(results_path)","metadata":{"execution":{"iopub.status.busy":"2022-08-27T14:55:42.187228Z","iopub.execute_input":"2022-08-27T14:55:42.187623Z","iopub.status.idle":"2022-08-27T14:55:42.194047Z","shell.execute_reply.started":"2022-08-27T14:55:42.187588Z","shell.execute_reply":"2022-08-27T14:55:42.192546Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Question 2 <br> <span style=\"font-size:3.9mm;\">Manually insert questions</span>","metadata":{}},{"cell_type":"code","source":"# Load model\nmodel_max_len=256\nbest_model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\nbest_model_dict_path= f\"/kaggle/input/bert-qna-{model_max_len}-squadv1/DistilBertSquad1_stateDict_ep2_DevF151.847.dict\"\nbest_model.load_state_dict(torch.load(best_model_dict_path))\nbest_model.to(device)   \nm = best_model.eval()\n\n# Load tokenizer\ntokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\ntokenizer.model_max_length=model_max_len\n# Handmade short context & questions evaluation\ntext = \"I am Theatina, I live in Athens and I believe life is an illusion !!\"\nprint(f\"\\nText: {text}\\n\")\n\n\nquestion = \"What's my name?\"\nanswer=answer_a_question(question, text, tokenizer, best_model)\nprint(f\"Question: {question}\\nPredicted answer: {answer}\\n\")\n\nquestion = \"What do I believe?\"\nanswer=answer_a_question(question, text, tokenizer, best_model)\nprint(f\"Question: {question}\\nPredicted answer: {answer}\\n\")\n\nquestion = \"Where does Theatina live?\"\nanswer=answer_a_question(question, text, tokenizer, best_model)\nprint(f\"Question: {question}\\nPredicted answer: {answer}\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2022-08-27T16:54:20.480735Z","iopub.execute_input":"2022-08-27T16:54:20.481831Z","iopub.status.idle":"2022-08-27T16:54:25.809857Z","shell.execute_reply.started":"2022-08-27T16:54:20.481795Z","shell.execute_reply":"2022-08-27T16:54:25.808732Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nText: I am Theatina, I live in Athens and I believe life is an illusion !!\n\nQuestion: What's my name?\nPredicted answer: Theatina\n\nQuestion: What do I believe?\nPredicted answer: Life is illusion\n\nQuestion: Where does Theatina live?\nPredicted answer: Athens\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Question 3 <br> <span style=\"font-size:3.9mm;\">200 randomly chosen questions from training set</span>","metadata":{}},{"cell_type":"code","source":"# Load model\nmodel_max_len=256\nbest_model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\nbest_model_dict_path= f\"/kaggle/input/bert-qna-{model_max_len}-squadv1/DistilBertSquad1_stateDict_ep2_DevF151.847.dict\"\nbest_model.load_state_dict(torch.load(best_model_dict_path))\nbest_model.to(device)   \nm = best_model.eval()\n\n# Load tokenizer\ntokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\ntokenizer.model_max_length=model_max_len\n\n# load training set\nsquad_train_path = \"/kaggle/input/bert-code/bert/train-v1.1.json\"\ntrain_df = squad_df(squad_train_path)\nall_q_ids=train_df[\"id\"].values\n\n# randomly choose 200 questions\nN=200\nquestions_ids = sample(set(all_q_ids),N)\ntrain_df_200 = train_df[train_df['id'].isin(questions_ids)].reset_index(drop=True)\ntrain_df_200[\"g_answer\"] = [ a[0][\"text\"] for a in train_df_200[\"answers\"]]\ncontext_list = train_df_200[\"context\"].values\nquestion_list = train_df_200[\"question\"].values\ng_answer_list = train_df_200[\"g_answer\"].values\n\n# answer questions and keep predictions for evaluation\ntotal_predictions_list=[]\nq_logfile_str=\"\"\nem,f1=\"Yes\",0.0\nmean_em, mean_f1=0.0,0.0\nfor num,(c,q,g_answer) in enumerate(zip(context_list,question_list,g_answer_list)):\n    answer=answer_a_question(q, c, tokenizer, best_model)\n    total_predictions_list+=answer\n    \n    f1 = compute_f1(g_answer, answer)\n    mean_f1+=f1\n        \n    em_val = compute_exact_match(g_answer, answer)\n    mean_em+=em_val\n    \n    em = \"Yes\" if em_val else \"No\"\n    q_logfile_str+=f\"\\nQ{num+1}. {q}\\nPredicted answer: {answer}\\nGolder answer: {g_answer}\\n(F1: {f1*100:.2f}%  |  EM: {em})\\n\"\n    \nmean_f1=mean_f1/N\nmean_em=mean_em/N\nscore_str=f\"\\nMean F1: {mean_f1*100:.2f}%  |  Mean EM: {mean_em*100:.2f}%\\n\"\n\nlogfile=os.path.join(results_path, \"Train_200_questions.txt\")    \nwith open(logfile, \"w\", encoding=\"utf-8\") as writer:\n    writer.write(score_str+\"\\n\")\n    writer.write(q_logfile_str)\n    \nq_logfile_str_out=score_str+q_logfile_str\nprint(q_logfile_str_out)\n    \nFileLinks(\".\")","metadata":{"execution":{"iopub.status.busy":"2022-08-27T17:18:47.362387Z","iopub.execute_input":"2022-08-27T17:18:47.362775Z","iopub.status.idle":"2022-08-27T17:18:59.557311Z","shell.execute_reply.started":"2022-08-27T17:18:47.362742Z","shell.execute_reply":"2022-08-27T17:18:59.556292Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"['lady', 'gaga'] ['lady', 'gaga']\n['ban', 'bossy'] ['ban', 'bossy']\n['beyoncé', 's', 'pepsi', 'commercial'] ['beyonce', 's', 'pepsi', 'commercial']\n['starpower', 'beyoncé'] ['starpower', 'beyonce']\n['clementi'] []\n['human'] ['human']\n['calm'] ['calm']\n['atticus'] ['atticus']\n['evolved', 'from', 'pure', 'niche', 'market', 'of', 'small', 'scale', 'applications', 'towards', 'becoming', 'mainstream', 'electricity', 'source'] ['evolved', 'from', 'pure', 'niche', 'market', 'of', 'small', 'scale', 'applications', 'towards', 'becoming', 'mainstream', 'electricity', 'source']\n['1944'] ['1944']\n['over', 'century'] ['over', 'century']\n['sl', 'benfica', 'fc', 'porto', 'and', 'sporting', 'cp'] ['sl', 'benfica', 'fc', 'porto', 'and', 'sporting', 'cp']\n['andre', 'aboolian'] ['andre', 'aboolian']\n['unsatisfactoriness'] ['suffering']\n['kara', 'dioguardi'] ['kara', 'dioguardi']\n['olympia', 'greece'] ['olympia', 'greece']\n['ioc'] ['international', 'olympic', 'committee', 'ioc']\n['great', 'depression'] ['great', 'depression']\n['hud'] ['hud']\n['hauptschule'] ['students', 'attending', 'hauptschule']\n['national', 'polytechnic', 'school'] ['national', 'polytechnic', 'school']\n['spain', 'and', 'france'] ['spain', 'and', 'france']\n['1254'] ['1254']\n['1958'] ['1958']\n['september', '20', '1963'] ['september', '20', '1963']\n['80', '000', 'to', '70', '000', 'years', 'ago'] ['80', '000', 'to', '70', '000', 'years']\n['atomic', 'structure'] ['atomic', 'structure']\n['chrome'] ['chrome']\n['passive', 'voice'] ['passive', 'voice']\n['china'] ['united', 'states']\n['1950s'] ['1950s']\n['adult', 'standards'] ['adult', 'standards']\n['increase'] ['11', 'percent', 'increase']\n['library'] ['library']\n['iberia', 'and', 'north', 'africa'] ['iberia', 'and', 'north', 'africa']\n['16'] ['16']\n['1949'] ['1949']\n['president', 'of', 'nauru'] ['president', 'of', 'nauru']\n['unpredictable', 'and', 'dangerous', 'crevasses'] ['unpredictable', 'and', 'dangerous', 'crevasses']\n['diogo', 'cão'] ['diogo', 'cao']\n['east', 'indies'] ['east', 'indies']\n['about', 'twice'] ['about', 'twice', 'bandwidth']\n['medieval', 'warm', 'period'] []\n['reverend', 'martin', 'luther', 'king'] ['reverend', 'martin', 'luther', 'king', 'jr']\n['irish', 'potato', 'famine'] ['repeal', 'of', 'corn', 'laws']\n['49', '1', '°c', '120', '4', '°f'] ['49', '1', '°c', '120', '4', '°f']\n['zakat', 'and', 'khums'] ['zakat', 'and', 'khums']\n['35', 'years'] ['35']\n['23', '6'] ['23', '6']\n['silver'] ['silver']\n['17'] ['17']\n['1921'] ['1921']\n['high', 'electrical', 'conductivity'] ['high', 'electrical', 'conductivity']\n['artificial', 'refrigeration'] ['artificial', 'refrigeration']\n['gop', 'variety', 'theatre'] ['gop', 'variety', 'theatre']\n['allied', 'bombing'] ['allied', 'bombing']\n['five'] ['five']\n['2009'] ['2009']\n['at', 't'] ['at', 't']\n['late', 'model', 'soviet', 'tanks', 'and', 'jet', 'fighters'] ['late', 'model', 'soviet', 'tanks', 'and', 'jet', 'fighters']\n['single', 'box', 'of', 'bullets'] ['unique']\n['coal'] ['coal']\n['dormition'] ['dormition']\n['cfb'] ['cfb']\n['1', 'by', '1⁄2', 'mile', '1', '61', 'by', '0', '80', 'km'] ['1', 'by', '1⁄2', 'mile']\n['1', '000'] ['1', '000']\n['most', 'macs', 'from', '2007', 'and', 'later'] ['most', 'macs']\n['soviet', 'union'] ['soviet', 'union']\n['balloon', 'or', 'airship', 'guns'] ['balloon']\n['tecumseh'] ['tecumseh']\n['bone', 'tissue'] ['bone', 'tissue']\n['hume'] ['hume', 's', 'philosophical', 'concepts', 'that', 'directly', 'influenced', 'james', 'madison', 'and', 'thus', 'u', 's', 'constitution', 'and', 'as', 'popularised', 'by', 'dugald', 'stewart']\n['frederick', 'great'] ['frederick', 'great']\n['£340', 'million'] ['£340', 'million']\n['56'] ['56']\n['ineffective', 'assistance', 'of', 'counsel'] ['ineffective', 'assistance', 'of', 'counsel']\n['dog', 'bone'] ['dog', 'bone']\n['washington', 'state', 'ferries'] ['washington', 'state', 'ferries']\n['smith', 'kline', 'and', 'french'] ['smith', 'kline', 'and', 'french']\n['emulsion'] ['emulsion']\n['her', 'second', 'son', 'alfred'] ['alfred']\n['28', 'april', '1738'] ['28', 'april', '1738']\n['east', 'of', 'central', 'highlands'] ['east', 'of', 'central', 'highlands']\n['songs', 'of', 'land', 'of', 'israel'] ['songs', 'of', 'land', 'of', 'israel']\n['seleucid'] ['seleucid', 'empire']\n['through', '2027', '2028', 'academic', 'year'] ['additional', 'decade']\n['27'] ['27']\n['minister', 's', 'staircase'] ['minister', 's', 'staircase']\n['further', 'strengthened', 'and', 'smoothed', 'filament'] ['uniformity', 'and', 'strength', 'of', 'filaments', 'as', 'well', 'as', 'their', 'efficiency']\n['0', '0018', 'inches'] ['0', '0018', 'inches']\n['male'] ['male']\n['william', 'wrigley', 'jr'] ['william', 'wrigley', 'jr']\n['kpa'] ['u', 's', 'garrisons', 'in', 'japan', 'continually', 'dispatched', 'soldiers', 'and', 'materiel', 'to', 'reinforce', 'defenders', 'in', 'pusan', 'perimeter', 'tank', 'battalions', 'deployed', 'to', 'korea', 'directly', 'from', 'u', 's', 'mainland', 'from', 'port', 'of', 'san', 'francisco', 'to', 'port', 'of', 'pusan', 'largest', 'korean', 'port', 'by', 'late', 'august', 'pusan', 'perimeter', 'had', 'some', '500', 'medium', 'tanks', 'battle', 'ready', 'in', 'early', 'september', '1950', 'rok', 'army', 'and', 'un', 'command', 'forces', 'outnumbered', 'kpa', '180', '000', 'to', '100', '000', 'soldiers', 'un', 'forces']\n['mere', 'conduit'] ['mere', 'conduit']\n['thailand', 'and', 'indonesia'] ['thailand', 'and', 'indonesia']\n['w', 't', 'f'] ['w', 't', 'f']\n['mexican–american', 'war'] ['mexican', '–', 'american', 'war']\n['paralyzed', 'by', 'its', 'own', 'bureaucracy', 'and', 'corruption'] ['it', 'proved', 'to', 'be', 'disaster', 'politically']\n['capital', 'en', 'movimiento'] ['capital', 'en', 'movimiento']\n['frisians'] ['frisians']\n['union', 'station'] ['union', 'station']\n['500'] ['500']\n['excessive', 'form', 'of', 'sweating'] ['excessive', 'form', 'of', 'sweating']\n['at', 'turn', 'of', '19th', 'century'] ['turn', 'of', '19th', 'century']\n['1807'] ['1807']\n['plants', 'of', 'medical', 'importance'] ['edible', 'medicinal', 'and', 'poisonous', 'plants']\n['up', 'to', '100', '000'] ['up', 'to', '100', '000']\n['guy', 'ritchie'] ['guy', 'ritchie']\n['1', '12', 'square', 'mile', '2', '9', 'km2'] ['1', '12', 'square', 'mile']\n['japan', 's', 'daiwa', 'institute', 'of', 'research', 'ltd', '30', '25', 'percent', 'and', 'japan', 'exchange', 'group', '18', '75', 'percent'] ['myanmar', 'signed', 'agreement', 'to', 'set', 'up', 'its', 'first', 'stock', 'exchange']\n['2013'] ['2013']\n['eastenders'] ['eastenders', 'eastbenders']\n['greater', 'realism'] ['greater', 'realism']\n['cefalù', 'cathedrals'] ['teruel']\n['chanakya'] ['chanakya']\n['thomas', 'edison'] ['thomas', 'edison']\n['1848'] ['1848']\n['majority', 'of', 'simplified', 'characters'] ['majority', 'of', 'simplified', 'characters']\n['romania', 'poland', 'lithuania', 'latvia', 'estonia', 'and', 'finland'] ['romania', 'poland', 'lithuania', 'latvia', 'estonia', 'and', 'finland']\n['big', 'science'] ['world', 'war', 'ii']\n['classical', 'conditioning'] ['discovered', 'classical', 'conditioning']\n['as', 'ice', 'reaches', 'sea', 'pieces', 'break', 'off', 'or', 'calve'] ['pieces', 'break', 'off', 'or', 'calve']\n['trend', 'micro'] ['trend', 'micro']\n['us', 'court', 'of', 'appeals', 'for', 'fifth', 'circuit'] ['us', 'court', 'of', 'appeals', 'for', 'fifth', 'circuit']\n['early', 'seventeenth', 'century', 'baptists'] ['early', 'seventeenth', 'century', 'baptists']\n['amish'] ['amish']\n['st', 'jago'] ['st', 'jago']\n['port', 'of', 'miami'] ['port', 'of', 'miami']\n['score', 'restored', 'feature', 'length', 'silent', 'film'] ['restored', 'feature', 'length', 'silent', 'film']\n['atheist', 'non', 'theistic'] ['atheist', 'non', 'theistic', 'hindu', 'philosophy']\n['vigo'] ['vigo']\n['21', '9'] ['21', '9']\n['secular', 'society'] ['secular']\n['2', '000'] ['2', '000']\n['panchala'] ['panchala', 'kingdom']\n['monumental'] ['monumental']\n['sher', 'shah', 'suri'] ['sher', 'shah', 'suri']\n['british'] ['british']\n['28', '32', 'and', '33'] ['28', '32', 'and', '33']\n['magnavox', 'vh', '8000'] ['magnavox', 'vh', '8000']\n['gods', 'represent', 'extension', 'of', 'human', 'social', 'life', 'to', 'include', 'supernatural', 'beings'] ['extension', 'of', 'human', 'social', 'life', 'to', 'include', 'supernatural', 'beings']\n['operation', 'enduring', 'freedom'] ['operation', 'enduring', 'freedom']\n['four'] ['four', 'times']\n['ladybugs'] ['ladybugs']\n['3', '5', 'million'] ['3', '5', 'million', 'people']\n['14'] ['14']\n['emishi'] ['emishi', 'people', 'lacked', 'motivation', 'and', 'discipline', 'and', 'failed', 'in', 'their', 'task', 'citation', 'needed', 'emperor', 'kammu', 'introduced', 'title', 'of', 'sei', 'i', 'taishogun', 'unk', 'unk', '大', 'unk', '軍', 'or', 'shogun', 'and', 'began', 'to', 'rely', 'on', 'powerful', 'regional', 'clans', 'to', 'conquer', 'emishi']\n['title', 'of', 'vice', 'governor', 'of', 'kazusa', 'province'] ['title', 'of', 'vice', 'governor', 'of', 'kazusa', 'province']\n['52', 'to', '69'] ['52', 'to', '69']\n['1945'] ['1945']\n['12', '570'] ['12', '570']\n['roman', 'catholicism'] []\n['savages'] ['savages']\n['reminiscent', 'of', 'more', 'famous', 'and', 'compact', 'struggle', 'of', '14th', 'century'] ['more', 'famous', 'and', 'compact', 'struggle', 'of', '14th', 'century']\n['austria', 'prussia', 'and', 'saxony'] ['austria', 'prussia', 'and', 'saxony']\n['astrophysicist'] ['astrophysicist']\n['single', 'bottom'] ['single', 'bottom']\n['300', '000'] ['300', '000']\n['in', '1846', 'republic', 'dissolved', 'when', 'texas', 'entered', 'united', 'states', 'of', 'america', 'as', 'state'] ['1846']\n['rice'] ['rice', 'cultivation']\n['1929'] ['1929']\n['attract', 'attention'] ['attract', 'attention']\n['butterflies'] ['butterflies']\n['place', 'al', 'makan', 'is', 'imagined', 'three', 'dimensional', 'void', 'between', 'inner', 'surfaces', 'of', 'containing', 'body'] ['place', 'al', 'makan', 'is', 'imagined', 'three', 'dimensional', 'void', 'between', 'inner', 'surfaces', 'of', 'containing', 'body']\n['europe'] ['europe']\n['united', 'kingdom', 'and', 'prussia'] []\n['jurchens'] ['jurchens']\n['reciprocal'] ['reciprocal']\n['1957'] ['1957']\n['josias', 'joesler'] ['josias', 'joesler']\n['muslim'] ['strict', 'muslim']\n['do', 'not'] []\n['pompey'] ['marcus', 'licinius', 'crassus', 'and', 'gnaeus', 'pompeius', 'magnus']\n['egyptian', 'revival'] ['one', 'of', 'few', 'egyptian', 'revival', 'buildings', 'in', 'united', 'states']\n['southwest'] ['southwest']\n['10', '65', 'inches', '271', 'mm'] ['10', 'inches']\n['372', '1'] ['372', '1']\n['museum', 'of', 'contemporary', 'art', 'san', 'diego', 'mcasd'] ['museum', 'of', 'contemporary', 'art', 'san', 'diego']\n['in', '1264', 'or', 'shortly', 'before'] ['1264']\n['supreme', 'leader'] ['supreme', 'leader']\n['isle', 'of', 'man'] ['isle', 'of', 'man']\n['in', 'country'] ['in', 'country']\n['may', '2014'] ['may', '2014']\n['seventy', 'translators'] ['seventy', 'translators']\n['cyclone', 'pam'] ['cyclone', 'pam']\n['1'] ['1']\n['songbirds', 'parrots'] ['songbirds', 'parrots', 'and', 'other', 'species']\n['eight'] ['eight']\n['calligraphy', 'and', 'painting'] ['orthodox', 'four', 'wangs']\n['caras', 'and', 'quitus'] ['caras', 'and', 'quitus']\n['mitochondrial', 'dna', 'and', 'y', 'chromosome'] ['y', 'chromosome']\n['varsity'] ['phase', 'in', 'one', 's', 'life', 'when', 'i', 'was', 'at', 'university', 'in', 'united', 'states', 'and', 'ireland', 'college', 'is', 'often', 'used', 'instead', 'when', 'i', 'was', 'in', 'college', 'in', 'australia', 'canada', 'new', 'zealand', 'united', 'kingdom', 'nigeria', 'netherlands', 'spain', 'and', 'german', 'speaking', 'countries', 'university', 'is', 'often', 'contracted', 'to', 'uni', 'in', 'ghana', 'new', 'zealand', 'and', 'in', 'south', 'africa', 'it', 'is', 'sometimes', 'called', 'varsity', 'although', 'this', 'has', 'become', 'uncommon', 'in', 'new', 'zealand', 'in', 'recent', 'years', 'varsity', 'was', 'also', 'common', 'usage', 'in', 'uk', 'in', '19th', 'century', 'citation', 'needed', 'varsity']\n['burned', 'at', 'stake'] ['burned', 'at', 'stake']\n['french'] ['french']\n['juscelino', 'kubitschek', 'de', 'oliveira'] ['juscelino', 'kubitschek', 'de', 'oliveira']\n['facilitate', 'relations', 'with', 'congress'] ['to', 'facilitate', 'relations', 'with', 'congress']\n['starting', 'in', 'late', '1980s'] ['late', '1980s']\n['unicameral'] ['unicameral']\n['make', 'kayaks', 'clothing', 'and', 'footwear'] ['to', 'make', 'kayaks', 'clothing', 'and', 'footwear']\n['hippopotamus'] ['antelope']\n\nMean F1: 81.40%  |  Mean EM: 68.00%\n\nQ1. Who else appeared with Beyonce in Telephone?\nPredicted answer: Lady gaga\nGolder answer: Lady Gaga\n(F1: 100.00%  |  EM: Yes)\n\nQ2. What campaign did she contribute to?\nPredicted answer: Ban bossy\nGolder answer: Ban Bossy\n(F1: 100.00%  |  EM: Yes)\n\nQ3. What influenced Nicki Minaj to join the Pepsi global campaign?\nPredicted answer: Beyonce s pepsi commercial\nGolder answer: Beyoncé's Pepsi commercial\n(F1: 75.00%  |  EM: No)\n\nQ4. What was the name of the video game that was cancelled for Beyonce?\nPredicted answer: Starpower beyonce\nGolder answer: Starpower: Beyoncé\n(F1: 50.00%  |  EM: No)\n\nQ5. Whose piano method did Chopin teach his students?\nPredicted answer: \nGolder answer: Clementi\n(F1: 0.00%  |  EM: No)\n\nQ6. Link's wolf form is faster than what other form?\nPredicted answer: Human\nGolder answer: human\n(F1: 100.00%  |  EM: Yes)\n\nQ7. How did a receptionist describe the atmosphere after the evacuation?\nPredicted answer: Calm\nGolder answer: calm\n(F1: 100.00%  |  EM: Yes)\n\nQ8. Who was the only non-abusive father mentioned?\nPredicted answer: Atticus\nGolder answer: Atticus\n(F1: 100.00%  |  EM: Yes)\n\nQ9. What has happened to photovoltaic in the past 20 years?\nPredicted answer: Evolved from pure niche market of small scale applications towards becoming mainstream electricity source\nGolder answer: evolved from a pure niche market of small scale applications towards becoming a mainstream electricity source\n(F1: 100.00%  |  EM: Yes)\n\nQ10. In which year was the first motorway opened in Portugal?\nPredicted answer: 1944\nGolder answer: 1944\n(F1: 100.00%  |  EM: Yes)\n\nQ11. For how long has the Libon tram service existed?\nPredicted answer: Over century\nGolder answer: over a century\n(F1: 100.00%  |  EM: Yes)\n\nQ12. What are the three largest sports clubs by popularity in Portugal?\nPredicted answer: Sl benfica fc porto and sporting cp\nGolder answer: SL Benfica, FC Porto, and Sporting CP\n(F1: 100.00%  |  EM: Yes)\n\nQ13. What doctor did Donda West ignore the recommendation of to invest her heart condition?\nPredicted answer: Andre aboolian\nGolder answer: Andre Aboolian\n(F1: 100.00%  |  EM: Yes)\n\nQ14. Dukkha can be translated as what word in regards to unhappiness?\nPredicted answer: Suffering\nGolder answer: unsatisfactoriness\n(F1: 0.00%  |  EM: No)\n\nQ15. Who was brought in as a new judge during American Idols eighth season?\nPredicted answer: Kara dioguardi\nGolder answer: Kara DioGuardi\n(F1: 100.00%  |  EM: Yes)\n\nQ16. Where is the location of the original Olympic events?\nPredicted answer: Olympia greece\nGolder answer: Olympia, Greece.\n(F1: 100.00%  |  EM: Yes)\n\nQ17. Who attended the celebrations?\nPredicted answer: International olympic committee ioc\nGolder answer: IOC\n(F1: 40.00%  |  EM: No)\n\nQ18. The financial crisis of 2007 was the worst economic crisis since which crisis that occurred in the 1930s?\nPredicted answer: Great depression\nGolder answer: Great Depression\n(F1: 100.00%  |  EM: Yes)\n\nQ19. Peter J. Wallison believes that the one of the roots of the financial crisis can be traced to affordable housing policies by which agency in the 1990s?\nPredicted answer: Hud\nGolder answer: HUD\n(F1: 100.00%  |  EM: Yes)\n\nQ20. At which school do students achieve the least success?\nPredicted answer: Students attending hauptschule\nGolder answer: Hauptschule\n(F1: 50.00%  |  EM: No)\n\nQ21. What school oversees the Quito Astronomical Observatory?\nPredicted answer: National polytechnic school\nGolder answer: National Polytechnic School\n(F1: 100.00%  |  EM: Yes)\n\nQ22. Between which two nations was the Treaty of the Pyrenees signed?\nPredicted answer: Spain and france\nGolder answer: Spain and France\n(F1: 100.00%  |  EM: Yes)\n\nQ23. In what year was Plymouth recognized as a town?\nPredicted answer: 1254\nGolder answer: 1254\n(F1: 100.00%  |  EM: Yes)\n\nQ24. The National Aeronautics and Space Act was established in what year?\nPredicted answer: 1958\nGolder answer: 1958\n(F1: 100.00%  |  EM: Yes)\n\nQ25. When did US President John F. Kennedy, in a speech, propose to join forces to reach the moon with the USSR?\nPredicted answer: September 20 1963\nGolder answer: September 20, 1963\n(F1: 100.00%  |  EM: Yes)\n\nQ26. How many years ago did hunting-gatherers start specializing in their collection practices?\nPredicted answer: 80 000 to 70 000 years\nGolder answer: 80,000 to 70,000 years ago\n(F1: 76.92%  |  EM: No)\n\nQ27. What theory is the hydrogen atom a big part of?\nPredicted answer: Atomic structure\nGolder answer: atomic structure\n(F1: 100.00%  |  EM: Yes)\n\nQ28. Which browser is the newest to enter the field?\nPredicted answer: Chrome\nGolder answer: Chrome\n(F1: 100.00%  |  EM: Yes)\n\nQ29. What do you not need to use in Catalan?\nPredicted answer: Passive voice\nGolder answer: passive voice\n(F1: 100.00%  |  EM: Yes)\n\nQ30. What country is leading in production of paper?\nPredicted answer: United states\nGolder answer: China\n(F1: 0.00%  |  EM: No)\n\nQ31. During what decade did rock and roll music first rise to popularity?\nPredicted answer: 1950s\nGolder answer: 1950s\n(F1: 100.00%  |  EM: Yes)\n\nQ32. What radio station format have many of the former soft AC artists moved to?\nPredicted answer: Adult standards\nGolder answer: adult standards\n(F1: 100.00%  |  EM: Yes)\n\nQ33. Was the GDP in 2013 an increase or decrease over 2012's levels?\nPredicted answer: 11 percent increase\nGolder answer: increase\n(F1: 50.00%  |  EM: No)\n\nQ34. What is one room in RIBA's headquarters that can be visited by the public?\nPredicted answer: Library\nGolder answer: the Library\n(F1: 100.00%  |  EM: Yes)\n\nQ35. Some Slavs migrated with the movement of the Vandals to where?\nPredicted answer: Iberia and north africa\nGolder answer: Iberia and north Africa\n(F1: 100.00%  |  EM: Yes)\n\nQ36. How many cities or towns are there in all of England and Wales with a ceremonial sheriff acting as the Mayor's deputy?\nPredicted answer: 16\nGolder answer: 16\n(F1: 100.00%  |  EM: Yes)\n\nQ37. In what year waas Vladan Dinic born?\nPredicted answer: 1949\nGolder answer: 1949\n(F1: 100.00%  |  EM: Yes)\n\nQ38. Who said that the Marshalls are the most endangered nation in the world?\nPredicted answer: President of nauru\nGolder answer: the president of Nauru\n(F1: 100.00%  |  EM: Yes)\n\nQ39. What does the cracking of the ice create?\nPredicted answer: Unpredictable and dangerous crevasses\nGolder answer: unpredictable and dangerous crevasses\n(F1: 100.00%  |  EM: Yes)\n\nQ40. What was the name of the Portuguese explorer?\nPredicted answer: Diogo cao\nGolder answer: Diogo Cão\n(F1: 50.00%  |  EM: No)\n\nQ41. China, Korea, southeast Asia and the islands of the Pacific were included in what? \nPredicted answer: East indies\nGolder answer: \"the East Indies\"\n(F1: 100.00%  |  EM: Yes)\n\nQ42. Efforts were made to reduce analog HDTV to how much of the bandwith of SDTV?\nPredicted answer: About twice bandwidth\nGolder answer: about twice\n(F1: 80.00%  |  EM: No)\n\nQ43. What event led to larger crop yields in the High Middle Ages?\nPredicted answer: \nGolder answer: the Medieval Warm Period\n(F1: 0.00%  |  EM: No)\n\nQ44. Who led the Civil Rights movement?\nPredicted answer: Reverend martin luther king jr\nGolder answer: Reverend Martin Luther King\n(F1: 88.89%  |  EM: No)\n\nQ45. What major event did The Times reluctantly support in the nineteenth century despite being initially opposed?\nPredicted answer: Repeal of corn laws\nGolder answer: Irish Potato Famine\n(F1: 0.00%  |  EM: No)\n\nQ46. What is the highest ever recorded temperature in New Delhi?\nPredicted answer: 49 1 °c 120 4 °f\nGolder answer: 49.1 °C (120.4 °F)\n(F1: 100.00%  |  EM: Yes)\n\nQ47. What did the deputies collect in the Imam's behalf?\nPredicted answer: Zakat and khums\nGolder answer: zakat and khums\n(F1: 100.00%  |  EM: Yes)\n\nQ48. What was the median age of Atlantic City?\nPredicted answer: 35\nGolder answer: 35 years\n(F1: 66.67%  |  EM: No)\n\nQ49. What percentage of the population in the city were living below the poverty line?\nPredicted answer: 23 6\nGolder answer: 23.6%\n(F1: 100.00%  |  EM: Yes)\n\nQ50. Which precious metal did Biezma discover?\nPredicted answer: Silver\nGolder answer: silver\n(F1: 100.00%  |  EM: Yes)\n\nQ51. Two-fifths of the state's territory was divided between how many families?\nPredicted answer: 17\nGolder answer: 17\n(F1: 100.00%  |  EM: Yes)\n\nQ52. The last census in Mexico that asked for race was carried out in which year?\nPredicted answer: 1921\nGolder answer: 1921\n(F1: 100.00%  |  EM: Yes)\n\nQ53. What is one property of copper that makes it so useful in electrical wiring?\nPredicted answer: High electrical conductivity\nGolder answer: high electrical conductivity\n(F1: 100.00%  |  EM: Yes)\n\nQ54. What technology support the drinking of chilled beer?\nPredicted answer: Artificial refrigeration\nGolder answer: artificial refrigeration\n(F1: 100.00%  |  EM: Yes)\n\nQ55. What famous theatre is located in Georgs Palace?\nPredicted answer: Gop variety theatre\nGolder answer: GOP Variety theatre\n(F1: 100.00%  |  EM: Yes)\n\nQ56. What destroyed the palace?\nPredicted answer: Allied bombing\nGolder answer: Allied bombing\n(F1: 100.00%  |  EM: Yes)\n\nQ57. How many competition wins did Barcelona have in 2011?\nPredicted answer: Five\nGolder answer: five\n(F1: 100.00%  |  EM: Yes)\n\nQ58. In what year did Everton take 7,000 travelling fans with them to an away game?\nPredicted answer: 2009\nGolder answer: 2009\n(F1: 100.00%  |  EM: Yes)\n\nQ59. What company introduced the first device to help deaf people communicate through telecommunications?\nPredicted answer: At t\nGolder answer: AT&T\n(F1: 100.00%  |  EM: Yes)\n\nQ60. What equipment did the Iraqi army possess?\nPredicted answer: Late model soviet tanks and jet fighters\nGolder answer: late model Soviet tanks and jet fighters\n(F1: 100.00%  |  EM: Yes)\n\nQ61. What precision did the FBI believe they could reach with chemical signatures?\nPredicted answer: Unique\nGolder answer: single box of bullets\n(F1: 0.00%  |  EM: No)\n\nQ62. What is the main mineral found on Antarctica?\nPredicted answer: Coal\nGolder answer: coal\n(F1: 100.00%  |  EM: Yes)\n\nQ63. What is another name for the Assumption of Mary?\nPredicted answer: Dormition\nGolder answer: Dormition\n(F1: 100.00%  |  EM: Yes)\n\nQ64. What is Melbourne's Koppen climate classification?\nPredicted answer: Cfb\nGolder answer: Cfb\n(F1: 100.00%  |  EM: Yes)\n\nQ65. What are the dimensions of the Hoddle Grid?\nPredicted answer: 1 by 1⁄2 mile\nGolder answer: 1 by 1⁄2 mile (1.61 by 0.80 km)\n(F1: 57.14%  |  EM: No)\n\nQ66. How many marks did John surrender?\nPredicted answer: 1 000\nGolder answer: 1,000\n(F1: 100.00%  |  EM: Yes)\n\nQ67. What computers is Maverick compatible with?\nPredicted answer: Most macs\nGolder answer: most Macs from 2007 and later\n(F1: 50.00%  |  EM: No)\n\nQ68. Which country had the most severe case?\nPredicted answer: Soviet union\nGolder answer: Soviet Union\n(F1: 100.00%  |  EM: Yes)\n\nQ69. What kind of guns started attracting attention?\nPredicted answer: Balloon\nGolder answer: balloon, or airship, guns\n(F1: 40.00%  |  EM: No)\n\nQ70. Who did the U.S. defeat to collapse the Indian Confederacy?\nPredicted answer: Tecumseh\nGolder answer: Tecumseh\n(F1: 100.00%  |  EM: Yes)\n\nQ71. Where does uranium accumulate in the body?\nPredicted answer: Bone tissue\nGolder answer: bone tissue\n(F1: 100.00%  |  EM: Yes)\n\nQ72. The basis of classical liberalism comes from whose philosophical concepts?\nPredicted answer: Hume s philosophical concepts that directly influenced james madison and thus u s constitution and as popularised by dugald stewart\nGolder answer: Hume\n(F1: 9.52%  |  EM: No)\n\nQ73. Which king of Prussia saw himself as the leader of the Enlightenment?\nPredicted answer: Frederick great\nGolder answer: Frederick the Great\n(F1: 100.00%  |  EM: Yes)\n\nQ74. What did the Sunday Times estimate Elizabeth's fortune to be in 2015?\nPredicted answer: £340 million\nGolder answer: £340 million\n(F1: 100.00%  |  EM: Yes)\n\nQ75. How old was Elizabeth's father at the time of his death?\nPredicted answer: 56\nGolder answer: 56\n(F1: 100.00%  |  EM: Yes)\n\nQ76. What is an example of an issue that is raised in collateral review?\nPredicted answer: Ineffective assistance of counsel\nGolder answer: ineffective assistance of counsel\n(F1: 100.00%  |  EM: Yes)\n\nQ77. What was the new design shape of the controller?\nPredicted answer: Dog bone\nGolder answer: dog bone\n(F1: 100.00%  |  EM: Yes)\n\nQ78. What organization runs the largest line of ferries in the US?\nPredicted answer: Washington state ferries\nGolder answer: Washington State Ferries\n(F1: 100.00%  |  EM: Yes)\n\nQ79. Who developed Amphetamine?\nPredicted answer: Smith kline and french\nGolder answer: Smith, Kline and French\n(F1: 100.00%  |  EM: Yes)\n\nQ80. What does mixing bitumen with water create?\nPredicted answer: Emulsion\nGolder answer: emulsion\n(F1: 100.00%  |  EM: Yes)\n\nQ81. Which of Queen Victoria's children died in July of that year? \nPredicted answer: Alfred\nGolder answer: her second son Alfred\n(F1: 40.00%  |  EM: No)\n\nQ82. When was the first Papal prounouncement against Freemasonry made?\nPredicted answer: 28 april 1738\nGolder answer: 28 April 1738\n(F1: 100.00%  |  EM: Yes)\n\nQ83. Where does the Jordan Rift Valley lie?\nPredicted answer: East of central highlands\nGolder answer: East of the central highlands\n(F1: 100.00%  |  EM: Yes)\n\nQ84. What the nation's canonical folk songs known as?\nPredicted answer: Songs of land of israel\nGolder answer: Songs of the Land of Israel\n(F1: 80.00%  |  EM: Yes)\n\nQ85. Armenia became a vassal state of what Empire?\nPredicted answer: Seleucid empire\nGolder answer: Seleucid\n(F1: 66.67%  |  EM: No)\n\nQ86. How long is the NU-Q branch of Northwestern scheduled to operate through an agreement in 2016?\nPredicted answer: Additional decade\nGolder answer: through the 2027-2028 academic year\n(F1: 0.00%  |  EM: No)\n\nQ87. What percentage of adults in the Netherlands spoke a dialect or regional language in 1995?\nPredicted answer: 27\nGolder answer: 27\n(F1: 100.00%  |  EM: Yes)\n\nQ88. The Belgian Suite is located at the bottom of which staircase?\nPredicted answer: Minister s staircase\nGolder answer: Minister's Staircase\n(F1: 100.00%  |  EM: Yes)\n\nQ89. What properties of graphite improved the filament?\nPredicted answer: Uniformity and strength of filaments as well as their efficiency\nGolder answer: further strengthened and smoothed the filament\n(F1: 13.33%  |  EM: No)\n\nQ90. What is the typical diameter of the filament on a 60-watt bulb?\nPredicted answer: 0 0018 inches\nGolder answer: 0.0018 inches\n(F1: 100.00%  |  EM: Yes)\n\nQ91. What gender's clothing is often more practical?\nPredicted answer: Male\nGolder answer: Male\n(F1: 100.00%  |  EM: Yes)\n\nQ92. Who had a majority interest in Cataline island  in 1919?\nPredicted answer: William wrigley jr\nGolder answer: William Wrigley Jr\n(F1: 100.00%  |  EM: Yes)\n\nQ93. Who had the fewest number of troops in Korea?\nPredicted answer: U s garrisons in japan continually dispatched soldiers and materiel to reinforce defenders in pusan perimeter tank battalions deployed to korea directly from u s mainland from port of san francisco to port of pusan largest korean port by late august pusan perimeter had some 500 medium tanks battle ready in early september 1950 rok army and un command forces outnumbered kpa 180 000 to 100 000 soldiers un forces\nGolder answer: KPA\n(F1: 2.82%  |  EM: No)\n\nQ94. In the E.U., what are the governing principles for ISP's?\nPredicted answer: Mere conduit\nGolder answer: mere conduit\n(F1: 100.00%  |  EM: Yes)\n\nQ95. Garuda is the national symbol of which 2 countries?\nPredicted answer: Thailand and indonesia\nGolder answer: Thailand and Indonesia\n(F1: 100.00%  |  EM: Yes)\n\nQ96. What episode of South Park dealt with wrestling?\nPredicted answer: W t f\nGolder answer: \"W.T.F.\"\n(F1: 100.00%  |  EM: Yes)\n\nQ97. What war did America and Mexico fight in?\nPredicted answer: Mexican – american war\nGolder answer: Mexican–American War\n(F1: 33.33%  |  EM: No)\n\nQ98. Why did the one-party government struggle after the major earthquake in 1985?\nPredicted answer: It proved to be disaster politically\nGolder answer: paralyzed by its own bureaucracy and corruption\n(F1: 0.00%  |  EM: No)\n\nQ99. What is the nickname of the city that the government is trying to push now?\nPredicted answer: Capital en movimiento\nGolder answer: Capital en Movimiento\n(F1: 100.00%  |  EM: Yes)\n\nQ100. What 6th tribe is sometimes included with the original 5 German tribes?\nPredicted answer: Frisians\nGolder answer: Frisians\n(F1: 100.00%  |  EM: Yes)\n\nQ101. At what terminal in New Haven was the Hartford Line slated to originate?\nPredicted answer: Union station\nGolder answer: Union Station\n(F1: 100.00%  |  EM: Yes)\n\nQ102. The recent Indiana Jones movie feature how many of the local citizen in film?\nPredicted answer: 500\nGolder answer: 500\n(F1: 100.00%  |  EM: Yes)\n\nQ103. What does diaphoresis refer to?\nPredicted answer: Excessive form of sweating\nGolder answer: excessive form of sweating\n(F1: 100.00%  |  EM: Yes)\n\nQ104. When did the idea of a \"consumer society\" begin? \nPredicted answer: Turn of 19th century\nGolder answer: at the turn of the 19th century.\n(F1: 88.89%  |  EM: No)\n\nQ105. When was the Slave Trade Act enacted?\nPredicted answer: 1807\nGolder answer: 1807\n(F1: 100.00%  |  EM: Yes)\n\nQ106. What kind of plants did monasteries cultivate?\nPredicted answer: Edible medicinal and poisonous plants\nGolder answer: plants of medical importance\n(F1: 22.22%  |  EM: No)\n\nQ107. How much was Madonna's nude photos were finally sold for?\nPredicted answer: Up to 100 000\nGolder answer: up to $100,000\n(F1: 100.00%  |  EM: Yes)\n\nQ108. Who is Madonna's second husband?\nPredicted answer: Guy ritchie\nGolder answer: Guy Ritchie\n(F1: 100.00%  |  EM: Yes)\n\nQ109. What is the approximate area of the core of the City of London?\nPredicted answer: 1 12 square mile\nGolder answer: 1.12-square-mile (2.9 km2)\n(F1: 72.73%  |  EM: No)\n\nQ110. Did other countries actively participate in business that first rang a bell to begin in the winter of 2014 in Myanmar ?\nPredicted answer: Myanmar signed agreement to set up its first stock exchange\nGolder answer: Japan's Daiwa Institute of Research Ltd 30.25 percent and Japan Exchange Group 18.75 percent.\n(F1: 7.41%  |  EM: No)\n\nQ111. In what year was The Sun's look changed?\nPredicted answer: 2013\nGolder answer: 2013\n(F1: 100.00%  |  EM: Yes)\n\nQ112. Which BBC show's homosexual kiss did The Sun report on?\nPredicted answer: Eastenders eastbenders\nGolder answer: EastEnders\n(F1: 66.67%  |  EM: No)\n\nQ113. What was achieved though the use of the scientific study of anatomy in the field of art?\nPredicted answer: Greater realism\nGolder answer: Greater realism\n(F1: 100.00%  |  EM: Yes)\n\nQ114. What is one cathedral in which the mixing of Romanesque, Gothic and Islamic styles can be seen?\nPredicted answer: Teruel\nGolder answer: Cefalù Cathedrals\n(F1: 0.00%  |  EM: No)\n\nQ115. Who was the 4th Century BC Indian political philosopher?\nPredicted answer: Chanakya\nGolder answer: Chanakya\n(F1: 100.00%  |  EM: Yes)\n\nQ116. Who did Sprague work for early in his career?\nPredicted answer: Thomas edison\nGolder answer: Thomas Edison\n(F1: 100.00%  |  EM: Yes)\n\nQ117. In what year did the Hungarian revolution take place?\nPredicted answer: 1848\nGolder answer: 1848\n(F1: 100.00%  |  EM: Yes)\n\nQ118. What are drawn from conventional abbreviated forms?\nPredicted answer: Majority of simplified characters\nGolder answer: majority of simplified characters\n(F1: 100.00%  |  EM: Yes)\n\nQ119. The agreement between the Nazis and the Soviets split what countries up?\nPredicted answer: Romania poland lithuania latvia estonia and finland\nGolder answer: Romania, Poland, Lithuania, Latvia, Estonia, and Finland\n(F1: 100.00%  |  EM: Yes)\n\nQ120. The atomic bomb was a part of which movement?\nPredicted answer: World war ii\nGolder answer: Big Science\n(F1: 0.00%  |  EM: No)\n\nQ121. What was Ivan Pavlov known for?\nPredicted answer: Discovered classical conditioning\nGolder answer: classical conditioning\n(F1: 80.00%  |  EM: No)\n\nQ122. How are icebergs formed?\nPredicted answer: Pieces break off or calve\nGolder answer: As the ice reaches the sea, pieces break off, or calve\n(F1: 71.43%  |  EM: No)\n\nQ123. Smartzone used what company's antivirus protection?\nPredicted answer: Trend micro\nGolder answer: Trend Micro\n(F1: 100.00%  |  EM: Yes)\n\nQ124. Who concluded that the University maintained a \"holistic\" approach to affirmative action?\nPredicted answer: Us court of appeals for fifth circuit\nGolder answer: US Court of Appeals for the Fifth Circuit\n(F1: 100.00%  |  EM: Yes)\n\nQ125. Who was thought to be influenced by continental Anabaptists?\nPredicted answer: Early seventeenth century baptists\nGolder answer: early seventeenth-century Baptists\n(F1: 100.00%  |  EM: Yes)\n\nQ126. What culture in the US benefits from this Act?\nPredicted answer: Amish\nGolder answer: Amish\n(F1: 100.00%  |  EM: Yes)\n\nQ127. Where was the first stop of the Beagle Expedition?\nPredicted answer: St jago\nGolder answer: St. Jago\n(F1: 100.00%  |  EM: Yes)\n\nQ128. What is the busiest cruise port in the world?\nPredicted answer: Port of miami\nGolder answer: Port of Miami\n(F1: 100.00%  |  EM: Yes)\n\nQ129. What is the grand prize in the Young Composers Film Competition?\nPredicted answer: Restored feature length silent film\nGolder answer: score a restored, feature-length silent film\n(F1: 90.91%  |  EM: No)\n\nQ130. What is the interpretation of classical  of Samkhya?\nPredicted answer: Atheist non theistic hindu philosophy\nGolder answer: atheist / non-theistic\n(F1: 75.00%  |  EM: No)\n\nQ131. Where did Sir Francis Drake attack in 1585 and again in 1589?\nPredicted answer: Vigo\nGolder answer: Vigo\n(F1: 100.00%  |  EM: Yes)\n\nQ132. How much of China's wine did Sichuan produce in 2000?\nPredicted answer: 21 9\nGolder answer: 21.9%\n(F1: 100.00%  |  EM: Yes)\n\nQ133. What type of society was seen that came from Raimon's 29 ways?\nPredicted answer: Secular\nGolder answer: secular society\n(F1: 66.67%  |  EM: No)\n\nQ134. How many many cheetah's are left in the wild?\nPredicted answer: 2 000\nGolder answer: 2,000\n(F1: 100.00%  |  EM: Yes)\n\nQ135. When the Kuru kingdom declined, to what kingdom did Vedic culture go?\nPredicted answer: Panchala kingdom\nGolder answer: Panchala\n(F1: 66.67%  |  EM: No)\n\nQ136. What kind of temples were built for Hindu Gods?\nPredicted answer: Monumental\nGolder answer: monumental\n(F1: 100.00%  |  EM: Yes)\n\nQ137. Who defeated Babur's son in 1540?\nPredicted answer: Sher shah suri\nGolder answer: Sher Shah Suri\n(F1: 100.00%  |  EM: Yes)\n\nQ138. Who has pressured the government to cancel the reception?\nPredicted answer: British\nGolder answer: British\n(F1: 100.00%  |  EM: Yes)\n\nQ139. Under which Scotland Act sections is the royal assent governed?\nPredicted answer: 28 32 and 33\nGolder answer: 28, 32, and 33\n(F1: 100.00%  |  EM: Yes)\n\nQ140. What was the first consumer VLP player?\nPredicted answer: Magnavox vh 8000\nGolder answer: Magnavox VH-8000\n(F1: 100.00%  |  EM: Yes)\n\nQ141. What did Émile Durkheim suggest about the existence of God?\nPredicted answer: Extension of human social life to include supernatural beings\nGolder answer: gods represent an extension of human social life to include supernatural beings\n(F1: 90.00%  |  EM: No)\n\nQ142. What was the name of the US's Afghanistan operation?\nPredicted answer: Operation enduring freedom\nGolder answer: Operation Enduring Freedom\n(F1: 100.00%  |  EM: Yes)\n\nQ143. How many instances has Estonia appeared in the EuroBasket tournament?\nPredicted answer: Four times\nGolder answer: four\n(F1: 66.67%  |  EM: No)\n\nQ144. What insect feeds on aphids?\nPredicted answer: Ladybugs\nGolder answer: ladybugs\n(F1: 100.00%  |  EM: Yes)\n\nQ145. What is roughly the amount of African slaves imported to Brazil?\nPredicted answer: 3 5 million people\nGolder answer: 3.5 million\n(F1: 85.71%  |  EM: No)\n\nQ146. IBM has how many members on its Board of Directors?\nPredicted answer: 14\nGolder answer: 14\n(F1: 100.00%  |  EM: Yes)\n\nQ147. Who did Kammu fail to conquer?\nPredicted answer: Emishi people lacked motivation and discipline and failed in their task citation needed emperor kammu introduced title of sei i taishogun unk unk 大 unk 軍 or shogun and began to rely on powerful regional clans to conquer emishi\nGolder answer: Emishi\n(F1: 5.00%  |  EM: No)\n\nQ148. What did Kazusanosuke mean?\nPredicted answer: Title of vice governor of kazusa province\nGolder answer: a title of vice-governor of Kazusa province\n(F1: 85.71%  |  EM: Yes)\n\nQ149. Which of CBC's channels were required to be relocated or reduced in power?\nPredicted answer: 52 to 69\nGolder answer: 52 to 69\n(F1: 100.00%  |  EM: Yes)\n\nQ150. What year did the Nazi's fall in World War II?\nPredicted answer: 1945\nGolder answer: 1945\n(F1: 100.00%  |  EM: Yes)\n\nQ151. How much does the city spend per year per child?\nPredicted answer: 12 570\nGolder answer: $12,570\n(F1: 100.00%  |  EM: Yes)\n\nQ152. What religion was the general population converted to?\nPredicted answer: \nGolder answer: Roman Catholicism\n(F1: 0.00%  |  EM: No)\n\nQ153. What band played music similar to that of the early British post-punk bands of the late '70s as recently as 2010?\nPredicted answer: Savages\nGolder answer: Savages\n(F1: 100.00%  |  EM: Yes)\n\nQ154. What is the precedent for the \"Second Hundred Year's War?\nPredicted answer: More famous and compact struggle of 14th century\nGolder answer: reminiscent of the more famous and compact struggle of the 14th century\n(F1: 88.89%  |  EM: No)\n\nQ155. Who were the parties in the Treaty of Hubertusburg?\nPredicted answer: Austria prussia and saxony\nGolder answer: Austria, Prussia, and Saxony\n(F1: 100.00%  |  EM: Yes)\n\nQ156. What career did Joan hold?\nPredicted answer: Astrophysicist\nGolder answer: astrophysicist\n(F1: 100.00%  |  EM: Yes)\n\nQ157. Before the code change was enacted what was the only permitted hydraulic cylinder type?\nPredicted answer: Single bottom\nGolder answer: single-bottom\n(F1: 100.00%  |  EM: Yes)\n\nQ158. How many elevators are in Brazil?\nPredicted answer: 300 000\nGolder answer: 300,000\n(F1: 100.00%  |  EM: Yes)\n\nQ159. When did Texas become a state?\nPredicted answer: 1846\nGolder answer: In 1846, the Republic dissolved when Texas entered the United States of America as a state.\n(F1: 14.29%  |  EM: No)\n\nQ160. African slaves had great knowledge of the cultivation of what product?\nPredicted answer: Rice cultivation\nGolder answer: rice\n(F1: 66.67%  |  EM: No)\n\nQ161. What year was the Grace Memorial Bridge built?\nPredicted answer: 1929\nGolder answer: 1929\n(F1: 100.00%  |  EM: Yes)\n\nQ162. Red was chosen as part of the Nazi flag to do what?\nPredicted answer: Attract attention\nGolder answer: attract attention\n(F1: 100.00%  |  EM: Yes)\n\nQ163. What type of animal was being protected in the area that received the first HCP?\nPredicted answer: Butterflies\nGolder answer: butterflies\n(F1: 100.00%  |  EM: Yes)\n\nQ164. Ibn al-Haytham used geometry to demonstrate  what?\nPredicted answer: Place al makan is imagined three dimensional void between inner surfaces of containing body\nGolder answer: place (al-makan) is the imagined three-dimensional void between the inner surfaces of a containing body\n(F1: 100.00%  |  EM: Yes)\n\nQ165. The term \"great power\" was first used on which continent?\nPredicted answer: Europe\nGolder answer: Europe\n(F1: 100.00%  |  EM: Yes)\n\nQ166. What countries found their economic growth in early 20th century?\nPredicted answer: \nGolder answer: United Kingdom and Prussia\n(F1: 0.00%  |  EM: No)\n\nQ167. What were the Manchus originally named?\nPredicted answer: Jurchens\nGolder answer: Jurchens\n(F1: 100.00%  |  EM: Yes)\n\nQ168. What is called when the direction of the elctrical current does not make a difference to the current?\nPredicted answer: Reciprocal\nGolder answer: Reciprocal\n(F1: 100.00%  |  EM: Yes)\n\nQ169. When did Washington University begin construction of a complex of residential halls?\nPredicted answer: 1957\nGolder answer: 1957\n(F1: 100.00%  |  EM: Yes)\n\nQ170. Who designed the Broadway Village shopping center?\nPredicted answer: Josias joesler\nGolder answer: Josias Joesler\n(F1: 100.00%  |  EM: Yes)\n\nQ171. What type of social system was in place under the Ottoman Empire?\nPredicted answer: Strict muslim\nGolder answer: Muslim\n(F1: 66.67%  |  EM: No)\n\nQ172. Do bacteria have membrabe-bound organelles in their cytoplasm?\nPredicted answer: \nGolder answer: do not\n(F1: 0.00%  |  EM: No)\n\nQ173. Who was believed to have had a secret allegiance with enemies of Julius Caesar?\nPredicted answer: Marcus licinius crassus and gnaeus pompeius magnus\nGolder answer: Pompey\n(F1: 0.00%  |  EM: No)\n\nQ174. What is the architectural style of the 1845 Egyptian Building?\nPredicted answer: One of few egyptian revival buildings in united states\nGolder answer: Egyptian Revival\n(F1: 36.36%  |  EM: No)\n\nQ175. In what direction does one travel from Richmond to reach Southside Speedway?\nPredicted answer: Southwest\nGolder answer: southwest\n(F1: 100.00%  |  EM: Yes)\n\nQ176. What is the average annual precipitation along San Diego's coast?\nPredicted answer: 10 inches\nGolder answer: 10.65 inches (271 mm)\n(F1: 57.14%  |  EM: No)\n\nQ177. How many square miles does San Diego cover?\nPredicted answer: 372 1\nGolder answer: 372.1\n(F1: 100.00%  |  EM: Yes)\n\nQ178. What museum has a branch at the Santa Fe Depot?\nPredicted answer: Museum of contemporary art san diego\nGolder answer: Museum of Contemporary Art San Diego (MCASD)\n(F1: 92.31%  |  EM: No)\n\nQ179. In what year was Kitab al-Miraj likely translated into Latin?\nPredicted answer: 1264\nGolder answer: in 1264 or shortly before\n(F1: 33.33%  |  EM: No)\n\nQ180. In Iran, who has the final say in all matters directly related to the Supreme Leader?\nPredicted answer: Supreme leader\nGolder answer: the Supreme Leader\n(F1: 100.00%  |  EM: Yes)\n\nQ181. What is one of the three Crown Dependencies of the British Isles?\nPredicted answer: Isle of man\nGolder answer: Isle of Man\n(F1: 100.00%  |  EM: Yes)\n\nQ182. Where do Liberians of European decent live?\nPredicted answer: In country\nGolder answer: in the country\n(F1: 100.00%  |  EM: Yes)\n\nQ183. When did the Chinese government ban the purchase of Windows 8 products?\nPredicted answer: May 2014\nGolder answer: May 2014\n(F1: 100.00%  |  EM: Yes)\n\nQ184. Why is the translation of the Old Testament into Greek known as the Septuagint?\nPredicted answer: Seventy translators\nGolder answer: seventy translators\n(F1: 100.00%  |  EM: Yes)\n\nQ185. What event on Tuvalu made assistance to the population necessary?\nPredicted answer: Cyclone pam\nGolder answer: Cyclone Pam\n(F1: 100.00%  |  EM: Yes)\n\nQ186. How much of Namibia's land is arable?\nPredicted answer: 1\nGolder answer: 1%\n(F1: 100.00%  |  EM: Yes)\n\nQ187. Which birds are popular as pets?\nPredicted answer: Songbirds parrots and other species\nGolder answer: Songbirds, parrots\n(F1: 57.14%  |  EM: No)\n\nQ188. How many viceroys were there in China Proper?\nPredicted answer: Eight\nGolder answer: eight\n(F1: 100.00%  |  EM: Yes)\n\nQ189. Name two arts of the Four Arts?\nPredicted answer: Orthodox four wangs\nGolder answer: Calligraphy and painting\n(F1: 0.00%  |  EM: No)\n\nQ190. What two cultures unified to for an elaborate civilization?\nPredicted answer: Caras and quitus\nGolder answer: the Caras and the Quitus\n(F1: 100.00%  |  EM: Yes)\n\nQ191. What DNA analysis indicated the common ancestry of the Native Americans?\nPredicted answer: Y chromosome\nGolder answer: mitochondrial DNA and Y-Chromosome\n(F1: 57.14%  |  EM: No)\n\nQ192. Scotland is said to frequently refer to university as what?\nPredicted answer: Phase in one s life when i was at university in united states and ireland college is often used instead when i was in college in australia canada new zealand united kingdom nigeria netherlands spain and german speaking countries university is often contracted to uni in ghana new zealand and in south africa it is sometimes called varsity although this has become uncommon in new zealand in recent years varsity was also common usage in uk in 19th century citation needed varsity\nGolder answer: Varsity\n(F1: 2.41%  |  EM: No)\n\nQ193. How did Jan Hus die?\nPredicted answer: Burned at stake\nGolder answer: burned at the stake\n(F1: 100.00%  |  EM: Yes)\n\nQ194. What nationality was de Beauvoir?\nPredicted answer: French\nGolder answer: French\n(F1: 100.00%  |  EM: Yes)\n\nQ195. Who was the JK Bridge named for?\nPredicted answer: Juscelino kubitschek de oliveira\nGolder answer: Juscelino Kubitschek de Oliveira\n(F1: 100.00%  |  EM: Yes)\n\nQ196. Why did Eisenhower ignore McCarthy?\nPredicted answer: To facilitate relations with congress\nGolder answer: facilitate relations with Congress\n(F1: 88.89%  |  EM: No)\n\nQ197. When did the Bronx's economy regrow?\nPredicted answer: Late 1980s\nGolder answer: starting in the late 1980s\n(F1: 66.67%  |  EM: No)\n\nQ198. What kind of legislature is the Provincial Assembly?\nPredicted answer: Unicameral\nGolder answer: unicameral\n(F1: 100.00%  |  EM: Yes)\n\nQ199. How are the skins of sea mammals useful for people in the Arctic trap?\nPredicted answer: To make kayaks clothing and footwear\nGolder answer: make kayaks, clothing, and footwear\n(F1: 90.91%  |  EM: No)\n\nQ200. What animal numbers have increased in Botswana?\nPredicted answer: Antelope\nGolder answer: hippopotamus\n(F1: 0.00%  |  EM: No)\n\n","output_type":"stream"},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"./\n  __notebook_source__.ipynb\n./results/predictions/\n  model_preds.txt\n  Train_200_questions.txt","text/html":"./<br>\n&nbsp;&nbsp;<a href='./__notebook_source__.ipynb' target='_blank'>__notebook_source__.ipynb</a><br>\n./results/predictions/<br>\n&nbsp;&nbsp;<a href='./results/predictions/model_preds.txt' target='_blank'>model_preds.txt</a><br>\n&nbsp;&nbsp;<a href='./results/predictions/Train_200_questions.txt' target='_blank'>Train_200_questions.txt</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 📚 References\n\n[SQuAD: 100,000+ Questions for Machine Comprehension of Tex](https://nlp.stanford.edu/pubs/rajpurkar2016squad.pdf)<br>\n[Evaluating QA: Metrics, Predictions, and the Null Response](https://github.com/fastforwardlabs/ff14_blog/blob/master/_notebooks/2020-06-09-Evaluating_BERT_on_SQuAD.ipynb)<br>\n[How-to Fine-Tune a Q&A Transformer](https://towardsdatascience.com/how-to-fine-tune-a-q-a-transformer-86f91ec92997)<br>\n[NLP - Document Retrieval for Question Answering](https://www.kaggle.com/code/leomauro/nlp-document-retrieval-for-question-answering)<br>\n[DistilBERT base model (uncased) ](https://huggingface.co/distilbert-base-uncased)<br>\n[SQuAD v1.1](https://datarepository.wolframcloud.com/resources/SQuAD-v1.1)<br>\n[kamalkraj/BERT-SQuAD ](https://github.com/kamalkraj/BERT-SQuAD)<br>\n[Question answering](https://huggingface.co/docs/transformers/tasks/question_answering)<br>\n\n\n\n\n","metadata":{}}]}