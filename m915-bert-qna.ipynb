{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"___\n\n# M915 - Συστήματα Κατανόησης και Παραγωγής Κειμένου \n___\n### Kylafi Christina-Theano <br><br> LT1200012","metadata":{}},{"cell_type":"code","source":"# imports\n# essentials\nimport os\nimport random\nimport numpy as np\nfrom numpy import mean, std\nimport math\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport json\nfrom collections import Counter\nimport re, string, unicodedata\nimport pickle \nfrom datetime import datetime\nimport pytz\nfrom itertools import cycle\nfrom scipy import interp \nimport time\nimport copy\nimport json\nimport csv\nfrom ast import literal_eval\n\n# PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\n\n# SKLEARN\nimport sklearn\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import normalize, OneHotEncoder, label_binarize\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_squared_error, accuracy_score, f1_score, precision_score, recall_score, log_loss, plot_confusion_matrix, roc_curve, auc, roc_auc_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import utils\nfrom sklearn.svm import SVC\n\n# NLTK\nimport nltk\nfrom nltk import word_tokenize, sent_tokenize, FreqDist\nfrom nltk.corpus import stopwords\nfrom nltk.stem import LancasterStemmer, WordNetLemmatizer\nnltk.download\nnltk.download('wordnet')\nnltk.download('stopwords')\nfrom nltk.tokenize import TweetTokenizer\n\nimport ast\n!pip install datasets\nfrom datasets import load_metric\n\n# BERT\n# !pip install transformers\n# !pip install pytorch-pretrained-bert\n\nimport transformers\nfrom transformers.data.processors.squad import SquadV2Processor\nfrom transformers.data import squad_convert_examples_to_features\nfrom transformers import AutoTokenizer\nfrom transformers import BertTokenizer, BertModel, BertForPreTraining, BertTokenizerFast, AdamW, BertForQuestionAnswering, DistilBertTokenizer, DistilBertForQuestionAnswering, DistilBertTokenizerFast, DistilBertModel\nfrom torch.utils.data import DataLoader\nfrom transformers import AdamW\n# from tqdm import tqdm_notebook as tqdm\nfrom tqdm import tqdm\n\nimport warnings\n\n# MORE INSTALLATIONS & IMPORTS\n# !pip install yellowbrick\n# !pip install advertools\n# !pip install vaderSentiment\n# !pip install ekphrasis\n# !pip install tweet-preprocessor\n\nfrom wordcloud import WordCloud\n# import advertools as adv\n# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n# from ekphrasis.classes.segmenter import Segmenter\n# import preprocessor as p\nimport multiprocessing\nfrom shutil import copy\nimport seaborn as sns\nfrom gensim.models import Word2Vec\nfrom IPython.display import Image\nfrom ast import literal_eval\nfrom tqdm.notebook import tqdm\nfrom IPython.display import FileLink, FileLinks\n\nprint(\"\\nImports Done !\\n\")\n\n# Device settings\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(f\"Working on {device}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-27T15:56:38.788130Z","iopub.execute_input":"2022-07-27T15:56:38.788696Z","iopub.status.idle":"2022-07-27T15:57:00.985074Z","shell.execute_reply.started":"2022-07-27T15:56:38.788592Z","shell.execute_reply":"2022-07-27T15:57:00.984025Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.8.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.12.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.0)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\nImports Done !\n\nWorking on cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# Functions\ndef squad_df(file_path, record_path=['data','paragraphs','qas','answers']):\n    file = json.loads(open(file_path).read())\n    \n    # parsing different level's in the json file\n    js = pd.json_normalize(file, record_path)\n    m = pd.json_normalize(file, record_path[:-1])\n    r = pd.json_normalize(file,record_path[:-2])\n    \n    # combining it into single dataframe\n    idx = np.repeat(r['context'].values, r.qas.str.len())\n    m['context'] = idx\n    data = m[['id','context','question','answers']].set_index('id').reset_index()\n    data['context_id'] = data['context'].factorize()[0]\n    return data\n\n\n# Add answer end index\ndef add_ans_ind(qna_df):\n    texts = qna_df[\"context\"]\n    answers = qna_df[\"answers\"]\n    for row,(text,answers) in enumerate(zip(texts,answers)):\n        for a_num,a in enumerate(answers):\n            a_text = a[\"text\"]\n            a_start = a[\"answer_start\"]\n            a_end = a_start\n            \n            a_end = int(a_start+len(a_text))\n            if text[a_start:a_end] == a_text:\n                qna_df.loc[row,\"answers\"][a_num][\"answer_end\"]=a_end\n            else:\n                if a_start==0:\n                    continue\n                else:\n                    if a_start==1:\n                        if text[a_start-1:a_end-1] == a_text:\n                            qna_df.loc[row,\"answers\"][a_num][\"answer_start\"]= a_start - 1\n                            qna_df.loc[row,\"answers\"][a_num][\"answer_end\"]= a_end - 1\n\n                    else:\n                        if text[a_start-2:a_end-2] == a_text:\n                            qna_df.loc[row,\"answers\"][a_num][\"answer_start\"]= a_start - 2\n                            qna_df.loc[row,\"answers\"][a_num][\"answer_end\"]= a_end - 2\n\n           \n    return qna_df\n\ndef add_token_positions(encodings, texts, starts, ends):\n    # initialize lists to contain the token indices of answer start/end\n    start_pos = []\n    end_pos = []\n    unanswerable_pos = tokenizer.model_max_length\n    for i,(text,start,end) in enumerate( zip(texts,starts,ends) ):\n        # unanswerable questions\n        if start==end==len(text):\n            start_pos.append(unanswerable_pos)\n            end_pos.append(unanswerable_pos)\n            continue\n        else:\n            start_pos.append(encodings.char_to_token(i, start))\n            end_pos.append(encodings.char_to_token(i, end))\n            if start_pos[-1] is None:\n                start_pos[-1] = unanswerable_pos\n                end_pos[-1] = unanswerable_pos\n                continue\n           \n            shift = 1\n            while end_pos[-1] is None and end-shift>start:\n                end_pos[-1] = encodings.char_to_token(i, end - shift)\n                shift += 1\n            if end_pos[-1] is None:\n                start_pos[-1] = unanswerable_pos\n                end_pos[-1] = unanswerable_pos\n\n    encodings.update({'start_positions': start_pos, 'end_positions': end_pos})\n\n# apply function to our data\n# add_token_positions(dev_encodings, list(qna_dev_df['AnswerStart']), list(qna_dev_df['AnswerEnd']))\n\n\ndef save_json_evalsquad1(total_preds,filepath=\"preds.json\", dev_set=\"/content/dev-v2.0.json\"):\n    with open(filepath, \"w\") as outfile:\n        json.dump(ast.literal_eval(json.dumps(total_preds)), outfile)\n    \n#     !python3 /content/evaluate-v2.0.py {dev_set} {filepath}\n    !python3 /kaggle/input/bert-code/bert/evaluate.py {dev_set} {filepath} \n\n    \ndef get_prediction(qid,total_preds):\n    return total_preds[qid]\n\ndef normalize_text(s):\n    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n    import string, re\n\n    def remove_articles(text):\n        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n        return re.sub(regex, \" \", text)\n\n    def white_space_fix(text):\n        return \" \".join(text.split())\n\n    def remove_punc(text):\n        exclude = set(string.punctuation)\n        return \"\".join(ch for ch in text if ch not in exclude)\n\n    def lower(text):\n        return text.lower()\n\n    return white_space_fix(remove_articles(remove_punc(lower(s))))\n\ndef compute_exact_match(prediction, truth):\n    return int(normalize_text(prediction) == normalize_text(truth))\n\ndef compute_f1(prediction, truth):\n    pred_tokens = normalize_text(prediction).split()\n    truth_tokens = normalize_text(truth).split()\n    \n    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n        return int(pred_tokens == truth_tokens)\n    \n    common_tokens = set(pred_tokens) & set(truth_tokens)\n    \n    # if there are no common tokens then f1 = 0\n    if len(common_tokens) == 0:\n        return 0\n    \n    prec = len(common_tokens) / len(pred_tokens)\n    rec = len(common_tokens) / len(truth_tokens)\n    \n    return 2 * (prec * rec) / (prec + rec)\n\n\n\ndef get_gold_answers(qid,id_to_answers):\n    \n    gold_answers = [answer[\"text\"] for answer in id_to_answers[qid] if answer[\"text\"]]\n\n    # if gold_answers doesn't exist it's because this is a negative example - \n    # the only correct answer is an empty string\n    if not gold_answers:\n        gold_answers = [\"\"]\n    \n    return gold_answers\n\ndef evalEMandF1_squad1(dev_df,total_preds):\n    global id_to_answers\n    questions = [  q for q in dev_df[\"question\"].values  ]\n    id_s = [ i for i in dev_df[\"id\"].values ]\n    answer_s = [ ans for ans in dev_df[\"answers\"].values ]\n    \n#     id_to_answers = {k:v for k,v in zip(id_s,answer_s)}\n    em_score = []\n    f1_score = []\n\n#   logfile for predictions and true answers\n    logfile_name = \"best_model_preds.txt\"\n    logfile_path = os.path.join( os.path.join(\"./Results/Logfiles\"),logfile_name)\n    logfile = open(logfile_path, \"w\", encoding=\"utf-8\")\n    logfile.write(\"Best Model Question Predictions on Dev Set\\n\")\n    for num,(qid,quest) in enumerate(zip(id_s,questions)):\n        prediction = get_prediction(qid,total_preds)\n        true_answers = get_gold_answers(qid,id_to_answers)\n\n        em_score.append(max((compute_exact_match(prediction, answer)) for answer in true_answers))\n        f1_score.append(max((compute_f1(prediction, answer)) for answer in true_answers))\n        \n        log_str = f\"\\n\\n{num+1}. Question: {quest}\\nTrue Answer(s): {true_answers}\\nPrediction(s): {prediction}\\nEM: {bool(int(em_score[-1]))}\\nF1: {f1_score[-1]*100:.2f}%\"\n        logfile.write(log_str)\n    \n    logfile.close()\n    \n    em = sum(em_score)/len(id_s)*100\n    f1_mean = sum(f1_score)/len(id_s)*100\n    f1_max = max(f1_score)*100\n    score_str = f\"Dev Set Scores -- \\tEM: {em:.2f}% \\tF1 (mean): {f1_mean:.2f}% \\tF1 (max): {f1_max:.2f}%\\n\"\n    print(score_str)\n    return em,f1_mean,f1_max,score_str\n\n\ndef total_preds_list(model,dev_dataset,device,dev_df):\n    global id_to_answers\n    model.to(device)\n    model.eval()\n    # initialize list to store epoch accuracies\n\n    total_preds = {}\n    acc = []\n    gtruth = {}\n    predictions = {}\n\n    batch_size=64\n    val_loader = DataLoader(dev_dataset, batch_size=batch_size)\n    id_list = [ i for i in dev_df[\"id\"].values ]\n    batch_sizes= [ len(val_b) for val_b in val_loader]\n    batches=val_loader.__len__\n    id_loader = [ id_list[i*batch_size:batch_size+i*batch_size] for i in range(batches-1) ]\n    id_loader.append([ id_list[- batch_sizes[-1] :] ])\n    print(id_loader, batch_sizes, batches)\n\n    # create a dictionary to link question id's with answers\n    questions = [  q for q in dev_df[\"question\"].values  ]\n#     id_list = [ i for i in dev_df[\"id\"].values ]\n    answer_s = [ ans for ans in dev_df[\"answers\"].values ]\n    \n    loss_dev = 0\n    loop_dev = tqdm(val_loader,leave=True)\n    for batch,ids in zip(val_loader, id_list):\n        # we don't need to calculate gradients as we're not training\n        with torch.no_grad():\n            # pull batched items from loader\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            # we will use true positions for accuracy calc\n    #         start_true = batch['start_positions'].to(device)\n    #         end_true = batch['end_positions'].to(device)\n            qid = ids\n            # make predictions\n            outputs = model(input_ids, attention_mask=attention_mask)\n#             loss = outputs[0]\n#             loss_dev += loss.item()\n    #         print(outputs['start_logits'])\n            # pull prediction tensors out and argmax to get predicted tokens\n            start_pred = torch.argmax(outputs['start_logits'], dim=1)\n            end_pred = torch.argmax(outputs['end_logits'], dim=1)\n\n    #         ans_pred_list = [ (question_id,p) for question_id,p in zip(qid,preds) ]\n            preds = [ tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[num][start_pred[num]:end_pred[num]])) for num in range(len(id_list)) ]\n            total_preds.update({ q:pred for q,pred in zip(qid,preds) })\n            \n            loop_dev.update(1)\n\n    return total_preds\n\n\ndef log_model(logfile,datetime_info,model,model_name,loss_func,optimizer,batch_size,normalization,max_s_len,pretrained):\n    separator = \"\".join([ \"_\" for i in range(50) ])\n    logstring = \"\"\n\n    # logstring+= f\"\\n\\n\\n\\n{separator}\\n{separator}\\n\\n\"\n    logstring+= f\"{datetime_info} - {model_name}\\n\\n\"\n    logstring+= f\"Features: {model.embedding.embedding_dim}\\n\"\n    logstring+= f\"Max Sentence length: {max_s_len}\\n\"\n    logstring+= f\"Pretrained Embeddings: {pretrained}\\n\"\n    logstring+= f\"Normalization: {normalization}\\n\"\n    # logstring+= f\"Epochs: {epochs}\\n\"\n    logstring+= f\"Batch size: {batch_size}\\n\"\n    logstring+= f\"Optimizer: {optimizer}\\n\"\n    logstring+= f\"Loss function: {loss_func}\"\n    if type(loss_func) == torch.nn.CrossEntropyLoss:\n        logstring+= f\", weight: {loss_func.weight}\\n\"\n    else :\n        logstring+= \"\\n\"\n        logstring+= f\"Layers: {model}\\n\\n\"\n        logstring+= f\"{separator}\\n\\n\"\n\n    logfile.write(logstring)\n\n\ndef log_score(logfile,epoch,model,score_str):\n    separator = \"\".join([ \"_\" for i in range(50) ])\n    logstring = \"\"\n\n    logstring+= f\"\\n\\n\\n> Epoch:{epoch}\\n\"\n    logstring+= score_str\n\n\n    logfile.write(logstring)\n\n\n# Logfiles\ndef get_file_ptr(drive_path,model_name):\n    tz = pytz.timezone('Europe/Athens')\n    datetime_info = f\"{datetime.now(tz):%d%m%y_%H%M}\"\n\n    logfile_name = f\"{model_name}__{datetime_info}.txt\"\n    model_logfile_dir_path = os.path.join(drive_path, f\"Results/Logfiles/{logfile_name[:-4]}\") \n    if not os.path.exists(model_logfile_dir_path):\n        os.makedirs(model_logfile_dir_path)  \n\n    logfile_path = os.path.join( os.path.join(model_logfile_dir_path),logfile_name)\n    logfile = open(logfile_path, \"w\", encoding=\"utf-8\")\n\n    return logfile, datetime_info, model_logfile_dir_path, logfile_path\n\n\ndef log_model_bert(logfile,datetime_info,model_name,optimizer,batch_size,max_s_len,train_len,val_len):\n    separator = \"\".join([ \"_\" for i in range(50) ])\n    logstring = \"\"\n\n    # logstring+= f\"\\n\\n\\n\\n{separator}\\n{separator}\\n\\n\"\n    logstring+= f\"{datetime_info} - {model_name}\\n\\n\"\n    logstring+= f\"Max Sentence length: {max_s_len}\\n\"\n    logstring+= f\"Batch size: {batch_size}\\n\"\n    logstring+= f\"Optimizer: {optimizer}\\n\"\n    logstring+= f\"Training Data: {train_len}\\n\"\n    logstring+= f\"Validation Data: {val_len}\\n\"\n    #   logstring+= f\"Layers: {model}\\n\\n\"\n    logstring+= f\"{separator}\\n\\n\"\n\n    logfile.write(logstring)\n  \n\n\ndef data_stats(df, type=\"Train\"):\n    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n    enc = tokenizer(list(df['context']), max_length=tokenizer.model_max_length, truncation=False )\n    lens=[ len(i_id) for i_id in enc[\"input_ids\"] ]\n    print(max(lens))\n    plt.figure(figsize=(18,12))\n    plt.grid(True)\n    plt.hist(lens)\n\n    return lens\n\n\n# pr_list = add_ans_ind(qna_train_df_quac)\n# pr_list = add_ans_ind(qna_dev_df_quac)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T18:00:26.554886Z","iopub.execute_input":"2022-07-27T18:00:26.555265Z","iopub.status.idle":"2022-07-27T18:00:26.643667Z","shell.execute_reply.started":"2022-07-27T18:00:26.555220Z","shell.execute_reply":"2022-07-27T18:00:26.642645Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# directories' paths\nsquad_train_path = \"/kaggle/input/bert-code/bert/train-v1.1.json\"\nsquad_dev_path = \"/kaggle/input/bert-code/bert/dev-v1.1.json\"\ntrain_df = squad_df(squad_train_path)\ndev_df = squad_df(squad_dev_path)\n\nresults_path = \"/kaggle/working/results\"\nif not os.path.exists(results_path):\n    os.makedirs(results_path)\n    \neval_v1_path = \"/kaggle/input/bert-code/bert/evaluate.py\"\neval_v2_path = \"/kaggle/input/httpsgithubcomsomiltgbert/evaluate-v2.0.py\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-27T17:20:08.409426Z","iopub.execute_input":"2022-07-27T17:20:08.409776Z","iopub.status.idle":"2022-07-27T17:20:15.941064Z","shell.execute_reply.started":"2022-07-27T17:20:08.409745Z","shell.execute_reply":"2022-07-27T17:20:15.940123Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.sample(frac=1).reset_index(drop=True)\ntrain_df = train_df[: int(train_df.shape[0]/4)]\nprint(train_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:20:15.943077Z","iopub.execute_input":"2022-07-27T17:20:15.943460Z","iopub.status.idle":"2022-07-27T17:20:15.994350Z","shell.execute_reply.started":"2022-07-27T17:20:15.943422Z","shell.execute_reply":"2022-07-27T17:20:15.993198Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"(21931, 5)\n","output_type":"stream"}]},{"cell_type":"code","source":"lens = data_stats(train_df)\nsum([i<256 for i in lens])/len(lens)*100","metadata":{"execution":{"iopub.status.busy":"2022-07-27T15:35:39.499661Z","iopub.execute_input":"2022-07-27T15:35:39.500180Z","iopub.status.idle":"2022-07-27T15:36:11.062504Z","shell.execute_reply.started":"2022-07-27T15:35:39.500129Z","shell.execute_reply":"2022-07-27T15:36:11.061266Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62b74c2a143a4588a73390c36241635d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e239ba1aedf1493c97ef4eec487053bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"980c261eebe6475b839ead2deba64e7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54b0cd4ccd7d4e62914f370add4846a6"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"512\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1296x864 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"# clean GPU cache\nimport gc\nimport torch\ndef clean_GPU_cache(print_sum=False):\n    if print_sum:  \n    print(\"\\nBefore\\n\")\n    print(torch.cuda.memory_summary(device=device, abbreviated=False))\n    torch.cuda.memory_summary(device=None, abbreviated=False)\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    if print_sum:  \n    print(\"\\n\\nAfter\\n\")\n    print(torch.cuda.memory_summary(device=device, abbreviated=False))\n\ndef check_gpu():\n    clean_GPU_cache()\n    print(\"\\n\")\n    !nvidia-smi\n    print(\"\\n\")\n\n# clean_GPU_cache()","metadata":{"execution":{"iopub.status.busy":"2022-07-27T15:57:07.944849Z","iopub.execute_input":"2022-07-27T15:57:07.945252Z","iopub.status.idle":"2022-07-27T15:57:07.969663Z","shell.execute_reply.started":"2022-07-27T15:57:07.945200Z","shell.execute_reply":"2022-07-27T15:57:07.966045Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# load distilBERT tokenizer & model\ntokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\ntokenizer.model_max_length = 256\n\n# tokenize\ntrain_encodings = tokenizer(list(train_df['context']), list(train_df['question']), max_length=tokenizer.model_max_length, truncation=\"only_first\", padding='max_length')\ndev_encodings = tokenizer(list(dev_df['context']), list(dev_df['question']), max_length=tokenizer.model_max_length, truncation=\"only_first\", padding='max_length')\n\n\n# id to answers dictionary\nglobal id_to_answers\nid_to_answers = { id_num:ans for id_num,ans in zip( dev_df[\"id\"].values, dev_df[\"answers\"].values ) }","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:20:29.432275Z","iopub.execute_input":"2022-07-27T17:20:29.432874Z","iopub.status.idle":"2022-07-27T17:20:49.524888Z","shell.execute_reply.started":"2022-07-27T17:20:29.432836Z","shell.execute_reply":"2022-07-27T17:20:49.523908Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# data processing\n# add end offset to the answers dictionaries\ntrain_df=add_ans_ind(train_df)\ndev_df=add_ans_ind(dev_df)\n\n# add_token_positions(train_encodings, qna_train_df[\"Text\"], list(qna_train_df['AnswerStart']), list(qna_train_df['AnswerEnd']))\nanswer_starts_train=[ ans[0][\"answer_start\"] for ans in train_df[\"answers\"].values ]\nanswer_ends_train=[ ans[0][\"answer_end\"] for ans in train_df[\"answers\"].values ]\ntrain_encodings.update({\"start\":answer_starts_train, \"end\":answer_ends_train})\n\nanswer_starts=[ ans[0][\"answer_start\"] for ans in dev_df[\"answers\"].values ]\nanswer_ends=[ ans[0][\"answer_end\"] for ans in dev_df[\"answers\"].values ]\ndev_encodings.update({\"start\":answer_starts, \"end\":answer_ends})\n\nadd_token_positions(train_encodings, train_df[\"context\"], answer_starts_train, answer_ends_train)\n\n# create dataaframes with useful information\ntrain_enc_df=pd.DataFrame({ k:train_encodings[k] for k in train_encodings.keys() })\ndev_enc_df=pd.DataFrame({ k:dev_encodings[k] for k in dev_encodings.keys() })\n\n# save encodings\n# train_df.to_csv(os.path.join(results_path,f\"SQuADv1_train_encodings_{tokenizer.model_max_length}.csv\"), index=False, header=True)\n# dev_df.to_csv(os.path.join(results_path,f\"SQuADv1_dev_encodings_{tokenizer.model_max_length}.csv\"), index=False, header=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:20:49.526776Z","iopub.execute_input":"2022-07-27T17:20:49.527103Z","iopub.status.idle":"2022-07-27T17:20:50.733235Z","shell.execute_reply.started":"2022-07-27T17:20:49.527077Z","shell.execute_reply":"2022-07-27T17:20:50.732277Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# load encodings df\n# train_enc_path=f\"/kaggle/input/squadv1-encodings-bert{tokenizer.model_max_length}/SQuADv1_train_encodings_{tokenizer.model_max_length}.csv\"\n# train_encodings=pd.read_csv(train_enc_path)\n# dev_enc_path=f\"/kaggle/input/squadv1-encodings-bert{tokenizer.model_max_length}/SQuADv1_dev_encodings_{tokenizer.model_max_length}.csv\"\n# dev_encodings=pd.read_csv(dev_enc_path)\n\n# # keep half the data due to computational complexity\n# train_encodings=train_encodings[:int(train_encodings.shape[0]/4)]\n# print(train_encodings.shape[0])\n\n# # converse to dictionaries\n# train_encodings={ k:train_encodings[k].values for k in train_encodings.columns  }\n# dev_encodings={ k:dev_encodings[k].values for k in dev_encodings.columns  }","metadata":{"execution":{"iopub.status.busy":"2022-07-27T16:53:24.348209Z","iopub.execute_input":"2022-07-27T16:53:24.348589Z","iopub.status.idle":"2022-07-27T16:53:25.627115Z","shell.execute_reply.started":"2022-07-27T16:53:24.348558Z","shell.execute_reply":"2022-07-27T16:53:25.626115Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"21931\n","output_type":"stream"}]},{"cell_type":"code","source":"class BERTinput(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, ind):\n        return {key: torch.tensor(value[ind]) for key,value in self.encodings.items()}\n\n    def __len__(self):\n        return len(self.encodings.input_ids)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-27T15:58:01.541367Z","iopub.execute_input":"2022-07-27T15:58:01.541969Z","iopub.status.idle":"2022-07-27T15:58:01.549570Z","shell.execute_reply.started":"2022-07-27T15:58:01.541930Z","shell.execute_reply":"2022-07-27T15:58:01.548496Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nclean_GPU_cache()\nbatch_size=32\n\n# build datasets for both our training and validation sets\ntrain_dataset = BERTinput(train_encodings)\ndev_dataset = BERTinput(dev_encodings)\n\n# initialize data loader for training data\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n# initialize validation set data loader\nval_loader = DataLoader(dev_dataset, batch_size=batch_size)\n\n# with open('/kaggle/working/results/train_loader.pickle', 'wb') as handle:\n#     pickle.dump(train_loader, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T18:02:08.010562Z","iopub.status.idle":"2022-07-27T18:02:08.012937Z","shell.execute_reply.started":"2022-07-27T18:02:08.012679Z","shell.execute_reply":"2022-07-27T18:02:08.012704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with open('filename.pickle', 'rb') as handle:\n#     b = pickle.load(handle)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model training\n\n# setup GPU/CPU\ncheck_gpu()\n\npretrained = 0\nif pretrained==0:\n    model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n    model.to(device)    \n    model_name = \"DistilBertSQuADv1\"\nelse:\n    model_name = \"DistilBertSQuADv1Pretrained\"\n\n\nmodel.train()\ntot_eps = 5\n# initialize adam optimizer with weight decay (reduces chance of overfitting)\nlr = 5e-4\n# optim = torch.optim.Adam(model.parameters(), lr=9e-6)\nweight_decay = 0.8\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n\nlogfile, datetime_info, model_logfile_dir_path, logfilefullpath = get_file_ptr(results_path,model_name)\nlog_model_bert(logfile,datetime_info,model_name,optimizer,batch_size,tokenizer.model_max_length,len(train_dataset),len(dev_dataset))\n\noverall_train_loss = []\noverall_dev_loss = []\nmax_f1_mean = -99\nem_scores = []\nf1_scores = []\nep = 0\nloss_dev = []\nfor epoch in range(tot_eps):\n    epoch_loss_train = 0\n    epoch_acc = 0\n    epoch_acc_dev = 0\n    epoch_loss_dev = 0\n    # set model to train mode\n    model.train()\n    # setup loop (we use tqdm for the progress bar)\n\n    loop = tqdm(train_loader, leave=True)\n    for batch in loop:\n        \n        # initialize calculated gradients (from prev step)\n        optimizer.zero_grad()\n        # pull all the tensor batches required for training\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        start_positions = batch['start_positions'].to(device)\n        end_positions = batch['end_positions'].to(device)\n        # train model on batch and return outputs (incl. loss)\n        outputs = model(input_ids, attention_mask=attention_mask,\n                        start_positions=start_positions,\n                        end_positions=end_positions)\n        # extract loss\n        loss = outputs[0]\n        # calculate loss for every parameter that needs grad update\n        loss.backward()\n        # update parameters\n        optimizer.step()\n        # print relevant info to progress bar\n        loop.set_description(f'Epoch {epoch+1}')\n        loop.set_postfix(loss=loss.item())\n        loop.update(1)\n        \n        epoch_loss_train += loss.item()\n        \n    \n    \n    ep_loss_train = epoch_loss_train / len(train_loader)\n#     ep_acc_dev = epoch_acc_dev / len(val_loader)\n    ep_loss_dev = epoch_loss_dev / len(val_loader)\n    \n\n    # keeping loss for learning curve plots\n    overall_train_loss.append(ep_loss_train)\n#     overall_dev_loss.append(ep_loss_dev)\n    \n\n    #     evaluation and EM & F1 scores\n    epoch_str = f'\\n----------------------- Epoch {epoch+1} / {tot_eps} -----------------------\\n' \n    print(epoch_str)\n    loss_str = f'Train Loss: {ep_loss_train:.3f}\\n'\n    print(loss_str)  \n    \n    tot_preds = total_preds_list(model,dev_dataset,device,dev_df)\n#     save_json_evalsquad2(tot_preds,filepath=\"preds.json\")\n    em,f1_mean,f1_max,score_str = evalEMandF1_squad1(dev_df,tot_preds)\n    em_scores.append(em)\n    f1_scores.append(f1_mean)\n    \n        # save best model\n    if f1_mean > max_f1_mean:\n        model_path = os.path.join(results_dir,f\"DistilBertSquad1_stateDict_ep{epoch+1}_DevF1{f1_mean:.3f}.dict\")\n        torch.save(model.state_dict(), model_path)\n#         model_path = os.path.join(model_logfile_dir_path,\"BertSquad2.h5\")\n#         torch.save(model, model_path)\n        \n        max_f1_mean = f1_mean\n        ep = epoch\n    \n#     val_str = f'\\t Val. Loss: {epoch_loss_dev:.3f} |  Val. Acc: {ep_acc_dev * 100:.2f}%\\n\\n'\n#     loss_str = f'Train Loss: {ep_loss_train:.3f} | Val. Loss: {ep_loss_dev:.3f} | Val. Acc: {ep_acc_dev * 100:.2f}%\\n\\n'\n    \n    \n#     write to logfile\n    logfile.write(\"\\n\"+epoch_str+loss_str)\n    logfile.write(\"\\n\"+score_str+\"\\n\\n\")\n    \n    \n# torch.save(model.state_dict(), PATH)\nlogfile.close()\nnew_dir_name = f\"{model_logfile_dir_path}_ep{ep+1}__DevF1{f1_scores[ep]:.2f}\"\nos.rename(model_logfile_dir_path,new_dir_name)      ","metadata":{"execution":{"iopub.status.idle":"2022-07-27T18:02:08.007445Z","shell.execute_reply.started":"2022-07-27T18:00:35.800105Z","shell.execute_reply":"2022-07-27T18:02:08.004767Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stderr","text":"\u001b[A\nEpoch 1:  20%|██        | 140/686 [00:47<03:03,  2.97it/s, loss=3.57]\u001b[A\nEpoch 1:  21%|██        | 141/686 [00:47<03:09,  2.87it/s, loss=3.57]\u001b[A\nEpoch 1:  21%|██        | 141/686 [00:48<03:09,  2.87it/s, loss=3.57]\u001b[A\nEpoch 1:  21%|██        | 141/686 [00:48<03:09,  2.87it/s, loss=3.65]\u001b[A\nEpoch 1:  21%|██        | 142/686 [00:48<03:14,  2.80it/s, loss=3.65]\u001b[A\nEpoch 1:  21%|██        | 142/686 [00:48<03:14,  2.80it/s, loss=3.65]\u001b[A\nEpoch 1:  21%|██        | 142/686 [00:48<03:14,  2.80it/s, loss=3.7] \u001b[A\nEpoch 1:  21%|██        | 143/686 [00:48<03:17,  2.75it/s, loss=3.7]\u001b[A\nEpoch 1:  21%|██        | 143/686 [00:49<03:17,  2.75it/s, loss=3.7]\u001b[A\nEpoch 1:  21%|██        | 143/686 [00:49<03:17,  2.75it/s, loss=3.53]\u001b[A\nEpoch 1:  21%|██        | 144/686 [00:49<03:19,  2.71it/s, loss=3.53]\u001b[A\nEpoch 1:  21%|██        | 144/686 [00:49<03:19,  2.71it/s, loss=3.53]\u001b[A\nEpoch 1:  21%|██        | 144/686 [00:49<03:19,  2.71it/s, loss=3.54]\u001b[A\nEpoch 1:  21%|██        | 145/686 [00:49<03:21,  2.68it/s, loss=3.54]\u001b[A\nEpoch 1:  21%|██        | 145/686 [00:49<03:21,  2.68it/s, loss=3.54]\u001b[A\nEpoch 1:  21%|██        | 145/686 [00:49<03:21,  2.68it/s, loss=3.7] \u001b[A\nEpoch 1:  21%|██▏       | 146/686 [00:49<03:22,  2.67it/s, loss=3.7]\u001b[A\nEpoch 1:  21%|██▏       | 146/686 [00:50<03:22,  2.67it/s, loss=3.7]\u001b[A\nEpoch 1:  21%|██▏       | 146/686 [00:50<03:22,  2.67it/s, loss=3.61]\u001b[A\nEpoch 1:  21%|██▏       | 147/686 [00:50<03:23,  2.65it/s, loss=3.61]\u001b[A\nEpoch 1:  21%|██▏       | 147/686 [00:50<03:23,  2.65it/s, loss=3.61]\u001b[A\nEpoch 1:  21%|██▏       | 147/686 [00:50<03:23,  2.65it/s, loss=3.68]\u001b[A\nEpoch 1:  22%|██▏       | 148/686 [00:50<03:23,  2.65it/s, loss=3.68]\u001b[A\nEpoch 1:  22%|██▏       | 148/686 [00:51<03:23,  2.65it/s, loss=3.68]\u001b[A\nEpoch 1:  22%|██▏       | 148/686 [00:51<03:23,  2.65it/s, loss=3.32]\u001b[A\nEpoch 1:  22%|██▏       | 149/686 [00:51<03:23,  2.64it/s, loss=3.32]\u001b[A\nEpoch 1:  22%|██▏       | 149/686 [00:51<03:23,  2.64it/s, loss=3.32]\u001b[A\nEpoch 1:  22%|██▏       | 149/686 [00:51<03:23,  2.64it/s, loss=3.5] \u001b[A\nEpoch 1:  22%|██▏       | 150/686 [00:51<03:23,  2.64it/s, loss=3.5]\u001b[A\nEpoch 1:  22%|██▏       | 150/686 [00:51<03:23,  2.64it/s, loss=3.5]\u001b[A\nEpoch 1:  22%|██▏       | 150/686 [00:51<03:23,  2.64it/s, loss=3.7]\u001b[A\nEpoch 1:  22%|██▏       | 151/686 [00:51<03:22,  2.64it/s, loss=3.7]\u001b[A\nEpoch 1:  22%|██▏       | 151/686 [00:52<03:22,  2.64it/s, loss=3.7]\u001b[A\nEpoch 1:  22%|██▏       | 151/686 [00:52<03:22,  2.64it/s, loss=3.47]\u001b[A\nEpoch 1:  22%|██▏       | 152/686 [00:52<03:22,  2.63it/s, loss=3.47]\u001b[A\nEpoch 1:  22%|██▏       | 152/686 [00:52<03:22,  2.63it/s, loss=3.47]\u001b[A\nEpoch 1:  22%|██▏       | 152/686 [00:52<03:22,  2.63it/s, loss=4.13]\u001b[A\nEpoch 1:  22%|██▏       | 153/686 [00:52<03:22,  2.63it/s, loss=4.13]\u001b[A\nEpoch 1:  22%|██▏       | 154/686 [00:52<03:22,  2.63it/s, loss=4.13]\u001b[A\nEpoch 1:  22%|██▏       | 154/686 [00:52<03:22,  2.63it/s, loss=3.66]\u001b[A\nEpoch 1:  23%|██▎       | 155/686 [00:52<02:35,  3.41it/s, loss=3.66]\u001b[A\nEpoch 1:  23%|██▎       | 155/686 [00:53<02:35,  3.41it/s, loss=3.66]\u001b[A\nEpoch 1:  23%|██▎       | 155/686 [00:53<02:35,  3.41it/s, loss=3.61]\u001b[A\nEpoch 1:  23%|██▎       | 156/686 [00:53<02:46,  3.18it/s, loss=3.61]\u001b[A\nEpoch 1:  23%|██▎       | 156/686 [00:53<02:46,  3.18it/s, loss=3.61]\u001b[A\nEpoch 1:  23%|██▎       | 156/686 [00:53<02:46,  3.18it/s, loss=3.32]\u001b[A\nEpoch 1:  23%|██▎       | 157/686 [00:53<02:55,  3.01it/s, loss=3.32]\u001b[A\nEpoch 1:  23%|██▎       | 157/686 [00:54<02:55,  3.01it/s, loss=3.32]\u001b[A\nEpoch 1:  23%|██▎       | 157/686 [00:54<02:55,  3.01it/s, loss=3.34]\u001b[A\nEpoch 1:  23%|██▎       | 158/686 [00:54<03:02,  2.89it/s, loss=3.34]\u001b[A\nEpoch 1:  23%|██▎       | 158/686 [00:54<03:02,  2.89it/s, loss=3.34]\u001b[A\nEpoch 1:  23%|██▎       | 158/686 [00:54<03:02,  2.89it/s, loss=3.32]\u001b[A\nEpoch 1:  23%|██▎       | 159/686 [00:54<03:08,  2.79it/s, loss=3.32]\u001b[A\nEpoch 1:  23%|██▎       | 159/686 [00:54<03:08,  2.79it/s, loss=3.32]\u001b[A\nEpoch 1:  23%|██▎       | 159/686 [00:54<03:08,  2.79it/s, loss=3.83]\u001b[A\nEpoch 1:  23%|██▎       | 160/686 [00:54<03:12,  2.74it/s, loss=3.83]\u001b[A\nEpoch 1:  23%|██▎       | 160/686 [00:55<03:12,  2.74it/s, loss=3.83]\u001b[A\nEpoch 1:  23%|██▎       | 160/686 [00:55<03:12,  2.74it/s, loss=3.84]\u001b[A\nEpoch 1:  23%|██▎       | 161/686 [00:55<03:14,  2.70it/s, loss=3.84]\u001b[A\nEpoch 1:  23%|██▎       | 161/686 [00:55<03:14,  2.70it/s, loss=3.84]\u001b[A\nEpoch 1:  23%|██▎       | 161/686 [00:55<03:14,  2.70it/s, loss=3.43]\u001b[A\nEpoch 1:  24%|██▎       | 162/686 [00:55<03:15,  2.68it/s, loss=3.43]\u001b[A\nEpoch 1:  24%|██▎       | 162/686 [00:56<03:15,  2.68it/s, loss=3.43]\u001b[A\nEpoch 1:  24%|██▎       | 162/686 [00:56<03:15,  2.68it/s, loss=3.63]\u001b[A\nEpoch 1:  24%|██▍       | 163/686 [00:56<03:17,  2.65it/s, loss=3.63]\u001b[A\nEpoch 1:  24%|██▍       | 163/686 [00:56<03:17,  2.65it/s, loss=3.63]\u001b[A\nEpoch 1:  24%|██▍       | 163/686 [00:56<03:17,  2.65it/s, loss=3.98]\u001b[A\nEpoch 1:  24%|██▍       | 164/686 [00:56<03:17,  2.65it/s, loss=3.98]\u001b[A\nEpoch 1:  24%|██▍       | 164/686 [00:56<03:17,  2.65it/s, loss=3.98]\u001b[A\nEpoch 1:  24%|██▍       | 164/686 [00:56<03:17,  2.65it/s, loss=4]   \u001b[A\nEpoch 1:  24%|██▍       | 165/686 [00:56<03:19,  2.61it/s, loss=4]\u001b[A\nEpoch 1:  24%|██▍       | 165/686 [00:57<03:19,  2.61it/s, loss=4]\u001b[A\nEpoch 1:  24%|██▍       | 165/686 [00:57<03:19,  2.61it/s, loss=3.55]\u001b[A\nEpoch 1:  24%|██▍       | 166/686 [00:57<03:22,  2.57it/s, loss=3.55]\u001b[A\nEpoch 1:  24%|██▍       | 166/686 [00:57<03:22,  2.57it/s, loss=3.55]\u001b[A\nEpoch 1:  24%|██▍       | 166/686 [00:57<03:22,  2.57it/s, loss=3.47]\u001b[A\nEpoch 1:  24%|██▍       | 167/686 [00:57<03:23,  2.55it/s, loss=3.47]\u001b[A\nEpoch 1:  24%|██▍       | 167/686 [00:57<03:23,  2.55it/s, loss=3.47]\u001b[A\nEpoch 1:  24%|██▍       | 167/686 [00:57<03:23,  2.55it/s, loss=3.59]\u001b[A\nEpoch 1:  24%|██▍       | 168/686 [00:57<03:24,  2.54it/s, loss=3.59]\u001b[A\nEpoch 1:  24%|██▍       | 168/686 [00:58<03:24,  2.54it/s, loss=3.59]\u001b[A\nEpoch 1:  24%|██▍       | 168/686 [00:58<03:24,  2.54it/s, loss=3.53]\u001b[A\nEpoch 1:  25%|██▍       | 169/686 [00:58<03:23,  2.55it/s, loss=3.53]\u001b[A\nEpoch 1:  25%|██▍       | 169/686 [00:58<03:23,  2.55it/s, loss=3.53]\u001b[A\nEpoch 1:  25%|██▍       | 169/686 [00:58<03:23,  2.55it/s, loss=3.37]\u001b[A\nEpoch 1:  25%|██▍       | 170/686 [00:58<03:21,  2.56it/s, loss=3.37]\u001b[A\nEpoch 1:  25%|██▍       | 170/686 [00:59<03:21,  2.56it/s, loss=3.37]\u001b[A\nEpoch 1:  25%|██▍       | 170/686 [00:59<03:21,  2.56it/s, loss=3.26]\u001b[A\nEpoch 1:  25%|██▍       | 171/686 [00:59<03:19,  2.58it/s, loss=3.26]\u001b[A\nEpoch 1:  25%|██▌       | 172/686 [00:59<03:19,  2.58it/s, loss=3.26]\u001b[A\nEpoch 1:  25%|██▌       | 172/686 [00:59<03:19,  2.58it/s, loss=3.11]\u001b[A\nEpoch 1:  25%|██▌       | 173/686 [00:59<02:32,  3.37it/s, loss=3.11]\u001b[A\nEpoch 1:  25%|██▌       | 173/686 [00:59<02:32,  3.37it/s, loss=3.11]\u001b[A\nEpoch 1:  25%|██▌       | 173/686 [00:59<02:32,  3.37it/s, loss=3.55]\u001b[A\nEpoch 1:  25%|██▌       | 174/686 [00:59<02:42,  3.14it/s, loss=3.55]\u001b[A\nEpoch 1:  25%|██▌       | 174/686 [01:00<02:42,  3.14it/s, loss=3.55]\u001b[A\nEpoch 1:  25%|██▌       | 174/686 [01:00<02:42,  3.14it/s, loss=3.47]\u001b[A\nEpoch 1:  26%|██▌       | 175/686 [01:00<02:50,  2.99it/s, loss=3.47]\u001b[A\nEpoch 1:  26%|██▌       | 175/686 [01:00<02:50,  2.99it/s, loss=3.47]\u001b[A\nEpoch 1:  26%|██▌       | 175/686 [01:00<02:50,  2.99it/s, loss=3.38]\u001b[A\nEpoch 1:  26%|██▌       | 176/686 [01:00<02:56,  2.88it/s, loss=3.38]\u001b[A\nEpoch 1:  26%|██▌       | 176/686 [01:01<02:56,  2.88it/s, loss=3.38]\u001b[A\nEpoch 1:  26%|██▌       | 176/686 [01:01<02:56,  2.88it/s, loss=3.42]\u001b[A\nEpoch 1:  26%|██▌       | 177/686 [01:01<03:01,  2.80it/s, loss=3.42]\u001b[A\nEpoch 1:  26%|██▌       | 177/686 [01:01<03:01,  2.80it/s, loss=3.42]\u001b[A\nEpoch 1:  26%|██▌       | 177/686 [01:01<03:01,  2.80it/s, loss=3.57]\u001b[A\nEpoch 1:  26%|██▌       | 178/686 [01:01<03:05,  2.74it/s, loss=3.57]\u001b[A\nEpoch 1:  26%|██▌       | 178/686 [01:01<03:05,  2.74it/s, loss=3.57]\u001b[A\nEpoch 1:  26%|██▌       | 178/686 [01:01<03:05,  2.74it/s, loss=3.37]\u001b[A\nEpoch 1:  26%|██▌       | 179/686 [01:01<03:07,  2.71it/s, loss=3.37]\u001b[A\nEpoch 1:  26%|██▌       | 179/686 [01:02<03:07,  2.71it/s, loss=3.37]\u001b[A\nEpoch 1:  26%|██▌       | 179/686 [01:02<03:07,  2.71it/s, loss=3.3] \u001b[A\nEpoch 1:  26%|██▌       | 180/686 [01:02<03:09,  2.68it/s, loss=3.3]\u001b[A\nEpoch 1:  26%|██▌       | 180/686 [01:02<03:09,  2.68it/s, loss=3.3]\u001b[A\nEpoch 1:  26%|██▌       | 180/686 [01:02<03:09,  2.68it/s, loss=3.16]\u001b[A\nEpoch 1:  26%|██▋       | 181/686 [01:02<03:09,  2.66it/s, loss=3.16]\u001b[A\nEpoch 1:  26%|██▋       | 181/686 [01:02<03:09,  2.66it/s, loss=3.16]\u001b[A\nEpoch 1:  26%|██▋       | 181/686 [01:02<03:09,  2.66it/s, loss=3.26]\u001b[A\nEpoch 1:  27%|██▋       | 182/686 [01:02<03:10,  2.65it/s, loss=3.26]\u001b[A\nEpoch 1:  27%|██▋       | 182/686 [01:03<03:10,  2.65it/s, loss=3.26]\u001b[A\nEpoch 1:  27%|██▋       | 182/686 [01:03<03:10,  2.65it/s, loss=3.29]\u001b[A\nEpoch 1:  27%|██▋       | 183/686 [01:03<03:10,  2.64it/s, loss=3.29]\u001b[A\nEpoch 1:  27%|██▋       | 183/686 [01:03<03:10,  2.64it/s, loss=3.29]\u001b[A\nEpoch 1:  27%|██▋       | 183/686 [01:03<03:10,  2.64it/s, loss=3.15]\u001b[A\nEpoch 1:  27%|██▋       | 184/686 [01:03<03:10,  2.64it/s, loss=3.15]\u001b[A\nEpoch 1:  27%|██▋       | 184/686 [01:04<03:10,  2.64it/s, loss=3.15]\u001b[A\nEpoch 1:  27%|██▋       | 184/686 [01:04<03:10,  2.64it/s, loss=3.42]\u001b[A\nEpoch 1:  27%|██▋       | 185/686 [01:04<03:10,  2.63it/s, loss=3.42]\u001b[A\nEpoch 1:  27%|██▋       | 185/686 [01:04<03:10,  2.63it/s, loss=3.42]\u001b[A\nEpoch 1:  27%|██▋       | 185/686 [01:04<03:10,  2.63it/s, loss=3.35]\u001b[A\nEpoch 1:  27%|██▋       | 186/686 [01:04<03:10,  2.62it/s, loss=3.35]\u001b[A\nEpoch 1:  27%|██▋       | 186/686 [01:04<03:10,  2.62it/s, loss=3.35]\u001b[A\nEpoch 1:  27%|██▋       | 186/686 [01:04<03:10,  2.62it/s, loss=3.41]\u001b[A\nEpoch 1:  27%|██▋       | 187/686 [01:04<03:10,  2.62it/s, loss=3.41]\u001b[A\nEpoch 1:  27%|██▋       | 187/686 [01:05<03:10,  2.62it/s, loss=3.41]\u001b[A\nEpoch 1:  27%|██▋       | 187/686 [01:05<03:10,  2.62it/s, loss=3.38]\u001b[A\nEpoch 1:  27%|██▋       | 188/686 [01:05<03:10,  2.62it/s, loss=3.38]\u001b[A\nEpoch 1:  27%|██▋       | 188/686 [01:05<03:10,  2.62it/s, loss=3.38]\u001b[A\nEpoch 1:  27%|██▋       | 188/686 [01:05<03:10,  2.62it/s, loss=3.25]\u001b[A\nEpoch 1:  28%|██▊       | 189/686 [01:05<03:09,  2.62it/s, loss=3.25]\u001b[A\nEpoch 1:  28%|██▊       | 189/686 [01:06<03:09,  2.62it/s, loss=3.25]\u001b[A\nEpoch 1:  28%|██▊       | 189/686 [01:06<03:09,  2.62it/s, loss=3.32]\u001b[A\nEpoch 1:  28%|██▊       | 190/686 [01:06<03:09,  2.62it/s, loss=3.32]\u001b[A\nEpoch 1:  28%|██▊       | 191/686 [01:06<03:08,  2.62it/s, loss=3.32]\u001b[A\nEpoch 1:  28%|██▊       | 191/686 [01:06<03:08,  2.62it/s, loss=3.13]\u001b[A\nEpoch 1:  28%|██▊       | 192/686 [01:06<02:25,  3.40it/s, loss=3.13]\u001b[A\nEpoch 1:  28%|██▊       | 192/686 [01:06<02:25,  3.40it/s, loss=3.13]\u001b[A\nEpoch 1:  28%|██▊       | 192/686 [01:06<02:25,  3.40it/s, loss=3.26]\u001b[A\nEpoch 1:  28%|██▊       | 193/686 [01:06<02:35,  3.17it/s, loss=3.26]\u001b[A\nEpoch 1:  28%|██▊       | 193/686 [01:07<02:35,  3.17it/s, loss=3.26]\u001b[A\nEpoch 1:  28%|██▊       | 193/686 [01:07<02:35,  3.17it/s, loss=3.39]\u001b[A\nEpoch 1:  28%|██▊       | 194/686 [01:07<02:43,  3.01it/s, loss=3.39]\u001b[A\nEpoch 1:  28%|██▊       | 194/686 [01:07<02:43,  3.01it/s, loss=3.39]\u001b[A\nEpoch 1:  28%|██▊       | 194/686 [01:07<02:43,  3.01it/s, loss=3.79]\u001b[A\nEpoch 1:  28%|██▊       | 195/686 [01:07<02:49,  2.89it/s, loss=3.79]\u001b[A\nEpoch 1:  28%|██▊       | 195/686 [01:07<02:49,  2.89it/s, loss=3.79]\u001b[A\nEpoch 1:  28%|██▊       | 195/686 [01:07<02:49,  2.89it/s, loss=3.3] \u001b[A\nEpoch 1:  29%|██▊       | 196/686 [01:07<02:54,  2.81it/s, loss=3.3]\u001b[A\nEpoch 1:  29%|██▊       | 196/686 [01:08<02:54,  2.81it/s, loss=3.3]\u001b[A\nEpoch 1:  29%|██▊       | 196/686 [01:08<02:54,  2.81it/s, loss=3.52]\u001b[A\nEpoch 1:  29%|██▊       | 197/686 [01:08<02:57,  2.76it/s, loss=3.52]\u001b[A\nEpoch 1:  29%|██▊       | 197/686 [01:08<02:57,  2.76it/s, loss=3.52]\u001b[A\nEpoch 1:  29%|██▊       | 197/686 [01:08<02:57,  2.76it/s, loss=3.26]\u001b[A\nEpoch 1:  29%|██▉       | 198/686 [01:08<02:59,  2.72it/s, loss=3.26]\u001b[A\nEpoch 1:  29%|██▉       | 198/686 [01:09<02:59,  2.72it/s, loss=3.26]\u001b[A\nEpoch 1:  29%|██▉       | 198/686 [01:09<02:59,  2.72it/s, loss=3.07]\u001b[A\nEpoch 1:  29%|██▉       | 199/686 [01:09<03:02,  2.67it/s, loss=3.07]\u001b[A\nEpoch 1:  29%|██▉       | 199/686 [01:09<03:02,  2.67it/s, loss=3.07]\u001b[A\nEpoch 1:  29%|██▉       | 199/686 [01:09<03:02,  2.67it/s, loss=3.43]\u001b[A\nEpoch 1:  29%|██▉       | 200/686 [01:09<03:04,  2.64it/s, loss=3.43]\u001b[A\nEpoch 1:  29%|██▉       | 200/686 [01:09<03:04,  2.64it/s, loss=3.43]\u001b[A\nEpoch 1:  29%|██▉       | 200/686 [01:09<03:04,  2.64it/s, loss=3.11]\u001b[A\nEpoch 1:  29%|██▉       | 201/686 [01:09<03:04,  2.63it/s, loss=3.11]\u001b[A\nEpoch 1:  29%|██▉       | 201/686 [01:10<03:04,  2.63it/s, loss=3.11]\u001b[A\nEpoch 1:  29%|██▉       | 201/686 [01:10<03:04,  2.63it/s, loss=3.03]\u001b[A\nEpoch 1:  29%|██▉       | 202/686 [01:10<03:04,  2.62it/s, loss=3.03]\u001b[A\nEpoch 1:  29%|██▉       | 202/686 [01:10<03:04,  2.62it/s, loss=3.03]\u001b[A\nEpoch 1:  29%|██▉       | 202/686 [01:10<03:04,  2.62it/s, loss=3.82]\u001b[A\nEpoch 1:  30%|██▉       | 203/686 [01:10<03:04,  2.62it/s, loss=3.82]\u001b[A\nEpoch 1:  30%|██▉       | 203/686 [01:10<03:04,  2.62it/s, loss=3.82]\u001b[A\nEpoch 1:  30%|██▉       | 203/686 [01:10<03:04,  2.62it/s, loss=3.59]\u001b[A\nEpoch 1:  30%|██▉       | 204/686 [01:11<03:03,  2.62it/s, loss=3.59]\u001b[A\nEpoch 1:  30%|██▉       | 204/686 [01:11<03:03,  2.62it/s, loss=3.59]\u001b[A\nEpoch 1:  30%|██▉       | 204/686 [01:11<03:03,  2.62it/s, loss=3.35]\u001b[A\nEpoch 1:  30%|██▉       | 205/686 [01:11<03:03,  2.63it/s, loss=3.35]\u001b[A\nEpoch 1:  30%|██▉       | 205/686 [01:11<03:03,  2.63it/s, loss=3.35]\u001b[A\nEpoch 1:  30%|██▉       | 205/686 [01:11<03:03,  2.63it/s, loss=3.48]\u001b[A\nEpoch 1:  30%|███       | 206/686 [01:11<03:02,  2.63it/s, loss=3.48]\u001b[A\nEpoch 1:  30%|███       | 206/686 [01:12<03:02,  2.63it/s, loss=3.48]\u001b[A\nEpoch 1:  30%|███       | 206/686 [01:12<03:02,  2.63it/s, loss=3.38]\u001b[A\nEpoch 1:  30%|███       | 207/686 [01:12<03:02,  2.63it/s, loss=3.38]\u001b[A\nEpoch 1:  30%|███       | 207/686 [01:12<03:02,  2.63it/s, loss=3.38]\u001b[A\nEpoch 1:  30%|███       | 207/686 [01:12<03:02,  2.63it/s, loss=3.53]\u001b[A\nEpoch 1:  30%|███       | 208/686 [01:12<03:02,  2.62it/s, loss=3.53]\u001b[A\nEpoch 1:  30%|███       | 208/686 [01:12<03:02,  2.62it/s, loss=3.53]\u001b[A\nEpoch 1:  30%|███       | 208/686 [01:12<03:02,  2.62it/s, loss=3.69]\u001b[A\nEpoch 1:  30%|███       | 209/686 [01:12<03:01,  2.62it/s, loss=3.69]\u001b[A\nEpoch 1:  30%|███       | 209/686 [01:13<03:01,  2.62it/s, loss=3.69]\u001b[A\nEpoch 1:  30%|███       | 209/686 [01:13<03:01,  2.62it/s, loss=3.5] \u001b[A\nEpoch 1:  31%|███       | 210/686 [01:13<03:01,  2.62it/s, loss=3.5]\u001b[A\nEpoch 1:  31%|███       | 211/686 [01:13<03:01,  2.62it/s, loss=3.5]\u001b[A\nEpoch 1:  31%|███       | 211/686 [01:13<03:01,  2.62it/s, loss=3.33]\u001b[A\nEpoch 1:  31%|███       | 212/686 [01:13<02:19,  3.40it/s, loss=3.33]\u001b[A\nEpoch 1:  31%|███       | 212/686 [01:14<02:19,  3.40it/s, loss=3.33]\u001b[A\nEpoch 1:  31%|███       | 212/686 [01:14<02:19,  3.40it/s, loss=3.08]\u001b[A\nEpoch 1:  31%|███       | 213/686 [01:14<02:29,  3.17it/s, loss=3.08]\u001b[A\nEpoch 1:  31%|███       | 213/686 [01:14<02:29,  3.17it/s, loss=3.08]\u001b[A\nEpoch 1:  31%|███       | 213/686 [01:14<02:29,  3.17it/s, loss=3.46]\u001b[A\nEpoch 1:  31%|███       | 214/686 [01:14<02:36,  3.01it/s, loss=3.46]\u001b[A\nEpoch 1:  31%|███       | 214/686 [01:14<02:36,  3.01it/s, loss=3.46]\u001b[A\nEpoch 1:  31%|███       | 214/686 [01:14<02:36,  3.01it/s, loss=3.39]\u001b[A\nEpoch 1:  31%|███▏      | 215/686 [01:14<02:43,  2.88it/s, loss=3.39]\u001b[A\nEpoch 1:  31%|███▏      | 215/686 [01:15<02:43,  2.88it/s, loss=3.39]\u001b[A\nEpoch 1:  31%|███▏      | 215/686 [01:15<02:43,  2.88it/s, loss=3.29]\u001b[A\nEpoch 1:  31%|███▏      | 216/686 [01:15<02:47,  2.81it/s, loss=3.29]\u001b[A\nEpoch 1:  31%|███▏      | 216/686 [01:15<02:47,  2.81it/s, loss=3.29]\u001b[A\nEpoch 1:  31%|███▏      | 216/686 [01:15<02:47,  2.81it/s, loss=3.2] \u001b[A\nEpoch 1:  32%|███▏      | 217/686 [01:15<02:50,  2.75it/s, loss=3.2]\u001b[A\nEpoch 1:  32%|███▏      | 217/686 [01:15<02:50,  2.75it/s, loss=3.2]\u001b[A\nEpoch 1:  32%|███▏      | 217/686 [01:15<02:50,  2.75it/s, loss=3.63]\u001b[A\nEpoch 1:  32%|███▏      | 218/686 [01:15<02:52,  2.71it/s, loss=3.63]\u001b[A\nEpoch 1:  32%|███▏      | 218/686 [01:16<02:52,  2.71it/s, loss=3.63]\u001b[A\nEpoch 1:  32%|███▏      | 218/686 [01:16<02:52,  2.71it/s, loss=3.3] \u001b[A\nEpoch 1:  32%|███▏      | 219/686 [01:16<02:54,  2.68it/s, loss=3.3]\u001b[A\nEpoch 1:  32%|███▏      | 219/686 [01:16<02:54,  2.68it/s, loss=3.3]\u001b[A\nEpoch 1:  32%|███▏      | 219/686 [01:16<02:54,  2.68it/s, loss=3.39]\u001b[A\nEpoch 1:  32%|███▏      | 220/686 [01:16<02:55,  2.66it/s, loss=3.39]\u001b[A\nEpoch 1:  32%|███▏      | 220/686 [01:17<02:55,  2.66it/s, loss=3.39]\u001b[A\nEpoch 1:  32%|███▏      | 220/686 [01:17<02:55,  2.66it/s, loss=3.35]\u001b[A\nEpoch 1:  32%|███▏      | 221/686 [01:17<02:55,  2.64it/s, loss=3.35]\u001b[A\nEpoch 1:  32%|███▏      | 221/686 [01:17<02:55,  2.64it/s, loss=3.35]\u001b[A\nEpoch 1:  32%|███▏      | 221/686 [01:17<02:55,  2.64it/s, loss=2.82]\u001b[A\nEpoch 1:  32%|███▏      | 222/686 [01:17<02:55,  2.64it/s, loss=2.82]\u001b[A\nEpoch 1:  32%|███▏      | 222/686 [01:17<02:55,  2.64it/s, loss=2.82]\u001b[A\nEpoch 1:  32%|███▏      | 222/686 [01:17<02:55,  2.64it/s, loss=3.29]\u001b[A\nEpoch 1:  33%|███▎      | 223/686 [01:17<02:55,  2.64it/s, loss=3.29]\u001b[A\nEpoch 1:  33%|███▎      | 223/686 [01:18<02:55,  2.64it/s, loss=3.29]\u001b[A\nEpoch 1:  33%|███▎      | 223/686 [01:18<02:55,  2.64it/s, loss=3.53]\u001b[A\nEpoch 1:  33%|███▎      | 224/686 [01:18<02:55,  2.64it/s, loss=3.53]\u001b[A\nEpoch 1:  33%|███▎      | 224/686 [01:18<02:55,  2.64it/s, loss=3.53]\u001b[A\nEpoch 1:  33%|███▎      | 224/686 [01:18<02:55,  2.64it/s, loss=3.43]\u001b[A\nEpoch 1:  33%|███▎      | 225/686 [01:18<02:55,  2.63it/s, loss=3.43]\u001b[A\nEpoch 1:  33%|███▎      | 225/686 [01:19<02:55,  2.63it/s, loss=3.43]\u001b[A\nEpoch 1:  33%|███▎      | 225/686 [01:19<02:55,  2.63it/s, loss=3.57]\u001b[A\nEpoch 1:  33%|███▎      | 226/686 [01:19<02:55,  2.62it/s, loss=3.57]\u001b[A\nEpoch 1:  33%|███▎      | 226/686 [01:19<02:55,  2.62it/s, loss=3.57]\u001b[A\nEpoch 1:  33%|███▎      | 226/686 [01:19<02:55,  2.62it/s, loss=3.38]\u001b[A\nEpoch 1:  33%|███▎      | 227/686 [01:19<02:54,  2.62it/s, loss=3.38]\u001b[A\nEpoch 1:  33%|███▎      | 227/686 [01:19<02:54,  2.62it/s, loss=3.38]\u001b[A\nEpoch 1:  33%|███▎      | 227/686 [01:19<02:54,  2.62it/s, loss=3.39]\u001b[A\nEpoch 1:  33%|███▎      | 228/686 [01:19<02:54,  2.62it/s, loss=3.39]\u001b[A\nEpoch 1:  33%|███▎      | 228/686 [01:20<02:54,  2.62it/s, loss=3.39]\u001b[A\nEpoch 1:  33%|███▎      | 228/686 [01:20<02:54,  2.62it/s, loss=2.88]\u001b[A\nEpoch 1:  33%|███▎      | 229/686 [01:20<02:56,  2.59it/s, loss=2.88]\u001b[A\nEpoch 1:  33%|███▎      | 229/686 [01:20<02:56,  2.59it/s, loss=2.88]\u001b[A\nEpoch 1:  33%|███▎      | 229/686 [01:20<02:56,  2.59it/s, loss=3.33]\u001b[A\nEpoch 1:  34%|███▎      | 230/686 [01:20<02:56,  2.58it/s, loss=3.33]\u001b[A\nEpoch 1:  34%|███▎      | 230/686 [01:20<02:56,  2.58it/s, loss=3.33]\u001b[A\nEpoch 1:  34%|███▎      | 230/686 [01:20<02:56,  2.58it/s, loss=3.5] \u001b[A\nEpoch 1:  34%|███▎      | 231/686 [01:20<02:55,  2.59it/s, loss=3.5]\u001b[A\nEpoch 1:  34%|███▍      | 232/686 [01:21<02:54,  2.59it/s, loss=3.5]\u001b[A\nEpoch 1:  34%|███▍      | 232/686 [01:21<02:54,  2.59it/s, loss=3.36]\u001b[A\nEpoch 1:  34%|███▍      | 233/686 [01:21<02:13,  3.39it/s, loss=3.36]\u001b[A\nEpoch 1:  34%|███▍      | 233/686 [01:21<02:13,  3.39it/s, loss=3.36]\u001b[A\nEpoch 1:  34%|███▍      | 233/686 [01:21<02:13,  3.39it/s, loss=3.32]\u001b[A\nEpoch 1:  34%|███▍      | 234/686 [01:21<02:23,  3.15it/s, loss=3.32]\u001b[A\nEpoch 1:  34%|███▍      | 234/686 [01:22<02:23,  3.15it/s, loss=3.32]\u001b[A\nEpoch 1:  34%|███▍      | 234/686 [01:22<02:23,  3.15it/s, loss=3.31]\u001b[A\nEpoch 1:  34%|███▍      | 235/686 [01:22<02:30,  2.99it/s, loss=3.31]\u001b[A\nEpoch 1:  34%|███▍      | 235/686 [01:22<02:30,  2.99it/s, loss=3.31]\u001b[A\nEpoch 1:  34%|███▍      | 235/686 [01:22<02:30,  2.99it/s, loss=3.11]\u001b[A\nEpoch 1:  34%|███▍      | 236/686 [01:22<02:36,  2.88it/s, loss=3.11]\u001b[A\nEpoch 1:  34%|███▍      | 236/686 [01:22<02:36,  2.88it/s, loss=3.11]\u001b[A\nEpoch 1:  34%|███▍      | 236/686 [01:22<02:36,  2.88it/s, loss=2.69]\u001b[A\nEpoch 1:  35%|███▍      | 237/686 [01:22<02:39,  2.81it/s, loss=2.69]\u001b[A\nEpoch 1:  35%|███▍      | 237/686 [01:23<02:39,  2.81it/s, loss=2.69]\u001b[A\nEpoch 1:  35%|███▍      | 237/686 [01:23<02:39,  2.81it/s, loss=3.26]\u001b[A\nEpoch 1:  35%|███▍      | 238/686 [01:23<02:43,  2.74it/s, loss=3.26]\u001b[A\nEpoch 1:  35%|███▍      | 238/686 [01:23<02:43,  2.74it/s, loss=3.26]\u001b[A\nEpoch 1:  35%|███▍      | 238/686 [01:23<02:43,  2.74it/s, loss=3.52]\u001b[A\nEpoch 1:  35%|███▍      | 239/686 [01:23<02:45,  2.70it/s, loss=3.52]\u001b[A\nEpoch 1:  35%|███▍      | 239/686 [01:24<02:45,  2.70it/s, loss=3.52]\u001b[A\nEpoch 1:  35%|███▍      | 239/686 [01:24<02:45,  2.70it/s, loss=2.93]\u001b[A\nEpoch 1:  35%|███▍      | 240/686 [01:24<02:46,  2.68it/s, loss=2.93]\u001b[A\nEpoch 1:  35%|███▍      | 240/686 [01:24<02:46,  2.68it/s, loss=2.93]\u001b[A\nEpoch 1:  35%|███▍      | 240/686 [01:24<02:46,  2.68it/s, loss=3.41]\u001b[A\nEpoch 1:  35%|███▌      | 241/686 [01:24<02:47,  2.66it/s, loss=3.41]\u001b[A\nEpoch 1:  35%|███▌      | 241/686 [01:24<02:47,  2.66it/s, loss=3.41]\u001b[A\nEpoch 1:  35%|███▌      | 241/686 [01:24<02:47,  2.66it/s, loss=3.71]\u001b[A\nEpoch 1:  35%|███▌      | 242/686 [01:24<02:47,  2.64it/s, loss=3.71]\u001b[A\nEpoch 1:  35%|███▌      | 242/686 [01:25<02:47,  2.64it/s, loss=3.71]\u001b[A\nEpoch 1:  35%|███▌      | 242/686 [01:25<02:47,  2.64it/s, loss=3.66]\u001b[A\nEpoch 1:  35%|███▌      | 243/686 [01:25<02:47,  2.64it/s, loss=3.66]\u001b[A\nEpoch 1:  35%|███▌      | 243/686 [01:25<02:47,  2.64it/s, loss=3.66]\u001b[A\nEpoch 1:  35%|███▌      | 243/686 [01:25<02:47,  2.64it/s, loss=3.42]\u001b[A\nEpoch 1:  36%|███▌      | 244/686 [01:25<02:48,  2.63it/s, loss=3.42]\u001b[A\nEpoch 1:  36%|███▌      | 244/686 [01:25<02:48,  2.63it/s, loss=3.42]\u001b[A\nEpoch 1:  36%|███▌      | 244/686 [01:25<02:48,  2.63it/s, loss=3.55]\u001b[A\nEpoch 1:  36%|███▌      | 245/686 [01:25<02:47,  2.63it/s, loss=3.55]\u001b[A\nEpoch 1:  36%|███▌      | 245/686 [01:26<02:47,  2.63it/s, loss=3.55]\u001b[A\nEpoch 1:  36%|███▌      | 245/686 [01:26<02:47,  2.63it/s, loss=3.39]\u001b[A\nEpoch 1:  36%|███▌      | 246/686 [01:26<02:47,  2.62it/s, loss=3.39]\u001b[A\nEpoch 1:  36%|███▌      | 246/686 [01:26<02:47,  2.62it/s, loss=3.39]\u001b[A\nEpoch 1:  36%|███▌      | 246/686 [01:26<02:47,  2.62it/s, loss=3.6] \u001b[A\nEpoch 1:  36%|███▌      | 247/686 [01:26<02:47,  2.62it/s, loss=3.6]\u001b[A\nEpoch 1:  36%|███▌      | 247/686 [01:27<02:47,  2.62it/s, loss=3.6]\u001b[A\nEpoch 1:  36%|███▌      | 247/686 [01:27<02:47,  2.62it/s, loss=3.79]\u001b[A\nEpoch 1:  36%|███▌      | 248/686 [01:27<02:47,  2.62it/s, loss=3.79]\u001b[A\nEpoch 1:  36%|███▌      | 248/686 [01:27<02:47,  2.62it/s, loss=3.79]\u001b[A\nEpoch 1:  36%|███▌      | 248/686 [01:27<02:47,  2.62it/s, loss=3.55]\u001b[A\nEpoch 1:  36%|███▋      | 249/686 [01:27<02:46,  2.62it/s, loss=3.55]\u001b[A\nEpoch 1:  36%|███▋      | 249/686 [01:27<02:46,  2.62it/s, loss=3.55]\u001b[A\nEpoch 1:  36%|███▋      | 249/686 [01:27<02:46,  2.62it/s, loss=3.74]\u001b[A\nEpoch 1:  36%|███▋      | 250/686 [01:27<02:46,  2.61it/s, loss=3.74]\u001b[A\nEpoch 1:  36%|███▋      | 250/686 [01:28<02:46,  2.61it/s, loss=3.74]\u001b[A\nEpoch 1:  36%|███▋      | 250/686 [01:28<02:46,  2.61it/s, loss=3.28]\u001b[A\nEpoch 1:  37%|███▋      | 251/686 [01:28<02:46,  2.62it/s, loss=3.28]\u001b[A\nEpoch 1:  37%|███▋      | 251/686 [01:28<02:46,  2.62it/s, loss=3.28]\u001b[A\nEpoch 1:  37%|███▋      | 251/686 [01:28<02:46,  2.62it/s, loss=3.48]\u001b[A\nEpoch 1:  34%|███▎      | 231/686 [01:28<02:55,  2.60it/s, loss=3.48]\u001b[A\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/1989195616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# calculate loss for every parameter that needs grad update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"FileLinks(model_logfile_dir_path)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:25:19.957130Z","iopub.status.idle":"2022-07-27T17:25:19.958050Z","shell.execute_reply.started":"2022-07-27T17:25:19.957773Z","shell.execute_reply":"2022-07-27T17:25:19.957798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLinks(\".\")","metadata":{"execution":{"iopub.status.busy":"2022-07-27T17:25:19.959831Z","iopub.status.idle":"2022-07-27T17:25:19.960325Z","shell.execute_reply.started":"2022-07-27T17:25:19.960067Z","shell.execute_reply":"2022-07-27T17:25:19.960089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 📚 References\n\n1. [text]()\n2. [text]()\n3. [text]()\n4. [text]()\n5. [text]()\n6. [NLP - Document Retrieval for Question Answering](https://www.kaggle.com/code/leomauro/nlp-document-retrieval-for-question-answering)\n7. [text]() \n8. [text]()\n9. [text]()\n10. [text]()\n11. [text]()\n12. [text]()\n13. [text]()\n14. [text]()\n15. [text]()\n16. [text]()\n17. [text]()\n\n","metadata":{}},{"cell_type":"code","source":"# eval_set = \"NewsQA\"\n# preds_file = f\"/content/Results/preds_ftune{ftune_set}_eval{eval_set}.json\"\n\n# total_preds = total_preds_list(model,dev_dataset,device,dev_df)\n\n# with open(preds_file, \"w\") as outfile:\n#     json.dump(ast.literal_eval(json.dumps(total_preds)), outfile)\n# !python3 {eval_file} ../input/squad2/dev-v2.0.json preds.json {preds_file} > ./ftune{ftune_set}_eval{eval_set}.txt\n# !python3 {eval_file} ../input/squad2/dev-v2.0.json preds.json {preds_file}","metadata":{"execution":{"iopub.status.busy":"2022-07-24T16:58:55.418626Z","iopub.execute_input":"2022-07-24T16:58:55.419316Z","iopub.status.idle":"2022-07-24T16:58:55.423796Z","shell.execute_reply.started":"2022-07-24T16:58:55.419277Z","shell.execute_reply":"2022-07-24T16:58:55.422732Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}